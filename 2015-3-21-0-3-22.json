[
    {
        "urllink": "http://arxiv.org/abs/1502.00030",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.00030",
        "title": "\nSHOE: Supervised Hashing with Output Embeddings",
        "abstract": "We present a supervised binary encoding scheme for image retrieval that learns projections by taking into account similarity between classes obtained from output embeddings. Our motivation is that binary hash codes learned in this way improve both the visual quality of retrieval results and existing supervised hashing schemes. We employ a sequential greedy optimization that learns relationship aware projections by minimizing the difference between inner products of binary codes and output embedding vectors. We develop a joint optimization framework to learn projections which improve the accuracy of supervised hashing over the current state of the art with respect to standard and sibling evaluation metrics. We further boost performance by applying the supervised dimensionality reduction technique on kernelized input CNN features. Experiments are performed on three datasets: CUB-2011, SUN-Attribute and ImageNet ILSVRC 2010. As a by-product of our method, we show that using a simple k-nn pooling classifier with our discriminative codes improves over the complex classification models on fine grained datasets like CUB and offer an impressive compression ratio of 1024 on CNN features.",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "authors": "Sravanthi Bondugula, Varun Manjunatha, Larry S. Davis, David Doermann,",
        "date": "2015-1-30"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.00033",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.00033",
        "title": "\nAnalyzing Interference from Static Cellular Cooperation using the  Nearest Neighbour Model",
        "abstract": "The problem of base station cooperation has recently been set within the framework of Stochastic Geometry. Existing works consider that a user dynamically chooses the set of stations that cooperate for his/her service. However, this assumption often does not hold. Cooperation groups could be predefined and static, with nodes connected by fixed infrastructure. To analyse such a potential network, in this work we propose a grouping method based on proximity. It is a variation of the so called Nearest Neighbour Model. We restrict ourselves to the simplest case where only singles and pairs of base stations are allowed to be formed. For this, two new point processes are defined from the dependent thinning of a Poisson Point Process, one for the singles and one for the pairs. Structural characteristics for the two are provided, including their density, Voronoi surface, nearest neighbour, empty space and J-function. We further make use of these results to analyse their interference fields and give explicit formulas to their expected value and their Laplace transform. The results constitute a novel toolbox towards the performance evaluation of networks with static cooperation.",
        "subjects": "Information Theory (cs.IT)",
        "authors": "Anastasios Giovanidis, Luis David Alvarez Corrales, Laurent Decreusefond,",
        "date": "2015-1-30"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.00045",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.00045",
        "title": "\nDomain-Type-Guided Refinement Selection Based on Sliced Path Prefixes",
        "abstract": "Abstraction is a successful technique in software verification, and interpolation on infeasible error paths is a successful approach to automatically detect the right level of abstraction in counterexample-guided abstraction refinement. Because the interpolants have a significant influence on the quality of the abstraction, and thus, the effectiveness of the verification, an algorithm for deriving the best possible interpolants is desirable. We present an analysis-independent technique that makes it possible to extract several alternative sequences of interpolants from one given infeasible error path, if there are several reasons for infeasibility in the error path. We take as input the given infeasible error path and apply a slicing technique to obtain a set of error paths that are more abstract than the original error path but still infeasible, each for a different reason. The (more abstract) constraints of the new paths can be passed to a standard interpolation engine, in order to obtain a set of interpolant sequences, one for each new path. The analysis can then choose from this set of interpolant sequences and select the most appropriate, instead of being bound to the single interpolant sequence that the interpolation engine would normally return. For example, we can select based on domain types of variables in the interpolants, prefer to avoid loop counters, or compare with templates for potential loop invariants, and thus control what kind of information occurs in the abstraction of the program. We implemented the new algorithm in the open-source verification framework CPAchecker and show that our proof-technique-independent approach yields a significant improvement of the effectiveness and efficiency of the verification process.",
        "subjects": "Software Engineering (cs.SE)",
        "authors": "Dirk Beyer, Stefan L\u00f6we, Philipp Wendler,",
        "date": "2015-1-31"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.00046",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.00046",
        "title": "\nMax-Margin Object Detection",
        "abstract": "Most object detection methods operate by applying a binary classifier to sub-windows of an image, followed by a non-maximum suppression step where detections on overlapping sub-windows are removed. Since the number of possible sub-windows in even moderately sized image datasets is extremely large, the classifier is typically learned from only a subset of the windows. This avoids the computational difficulty of dealing with the entire set of sub-windows, however, as we will show in this paper, it leads to sub-optimal detector performance. In particular, the main contribution of this paper is the introduction of a new method, Max-Margin Object Detection (MMOD), for learning to detect objects in images. This method does not perform any sub-sampling, but instead optimizes over all sub-windows. MMOD can be used to improve any object detection method which is linear in the learned parameters, such as HOG or bag-of-visual-word models. Using this approach we show substantial performance gains on three publicly available datasets. Strikingly, we show that a single rigid HOG filter can outperform a state-of-the-art deformable part model on the Face Detection Data Set and Benchmark when the HOG filter is learned via MMOD.",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "authors": "Davis E. King,",
        "date": "2015-1-31"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.00050",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.00050",
        "title": "\nTime-Free and Timer-Based Assumptions Can Be Combined to Solve  Authenticated Byzantine Consensus",
        "abstract": "To circumvent the FLP impossibility result in a deterministic way several protocols have been proposed on top of an asynchronous distributed system enriched with additional assumptions. In the context of Byzantine failures for systems where at most t processes may exhibit a Byzantine behavior, two approaches have been investigated to solve the consensus problem.The first, relies on the addition of synchrony, called Timer-Based, but the second is based on the pattern of the messages that are exchanged, called Time-Free. This paper shows that both types of assumptions are not antagonist and can be combined to solve authenticated Byzantine consensus. This combined assumption considers a correct process pi, called 2t-BW, and a set X of 2t processes such that, eventually, for each query broadcasted by a correct process pj of X, pj receives a response from pi 2 X among the (n- t) first responses to that query or both links connecting pi and pj are timely. Based on this combination, a simple hybrid authenticated Byzantine consensus protocol,benefiting from the best of both worlds, is proposed. Whereas many hybrid protocols have been designed for the consensus problem in the crash model, this is, to our knowledge, the first hybrid deterministic solution to the Byzantine consensus problem.",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "authors": "Hamouma Moumen,",
        "date": "2015-1-31"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.00052",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.00052",
        "title": "\nJoint Tx/Rx Energy-Efficient Scheduling in Multi-Radio Networks: A  Divide-and-Conque Approach",
        "abstract": "Most of the existing works on energy-efficient wireless communication systems only consider the transmitter (Tx) or the receiver (Rx) side power consumption but not both. Moreover, they often assume the static circuit power consumption. To be more practical, this paper considers the joint Tx and Rx power consumption in multiple-access radio networks, where the power model takes both the transmission power and the dynamic circuit power into account. We formulate the joint Tx and Rx energy efficiency (EE) maximization problem which is a combinatorial-type one due to the indicator function for scheduling users and activating radio links. The link EE and the user EE are then introduced which have the similar structure as the system EE. Their hierarchical relationships are exploited to tackle the problem using a divide-and-conquer approach, which is only of linear complexity. We further reveal that the static receiving power plays a critical role in the user scheduling. Finally, comprehensive numerical results are provided to validate the theoretical findings and demonstrate the effectiveness of the proposed algorithm for improving the system EE.",
        "subjects": "Information Theory (cs.IT)",
        "authors": "Qingqing Wu, Meixia Tao, Wen Chen,",
        "date": "2015-1-31"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.00054",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.00054",
        "title": "\nECPR: Environment- and Context-aware Combined Power and Rate Distributed  Congestion Control for Vehicular Communications",
        "abstract": "Safety and efficiency applications in vehicular networks rely on the exchange of periodic messages between vehicles. These messages contain position, speed, heading, and other vital information that makes the vehicles aware of their surroundings. The drawback of exchanging periodic cooperative messages is that they generate significant channel load. Decentralized Congestion Control (DCC) algorithms have been proposed to control the channel load. However, while the rationale for periodic message exchange is to improve awareness, existing DCC algorithms do not use awareness as a metric for deciding when, at what power, and at what rate the periodic messages need to be sent in order to make sure that the hard-to-reach vehicles are informed. We propose ECPR, an environment and context-aware DCC algorithm, which combines power and rate control to improve cooperative awareness by adapting to both specific propagation environments (such as urban intersections, open highways, suburban roads) as well as application requirements (e.g., different target cooperative awareness range). Using the current context that the vehicle operates in (e.g., speed, direction, and application requirement), ECPR adjusts the transmit power of the messages to reach the desired awareness ratio at the target distance while at the same time controlling the channel load using an adaptive rate control algorithm. By performing extensive simulations, including realistic propagation and environment modeling and realistic vehicle contexts (varying demand on both awareness range and rate), we show that ECPR can increase awareness by 20% while keeping the channel load and interference at almost the same level. When the awareness requirements allow, ECPR can improve the average message rate by 18% compared to algorithms that perform rate adaptation only.",
        "subjects": "Other Computer Science (cs.OH)",
        "authors": "Bengi Aygun, Mate Boban, Alexander M. Wyglinski,",
        "date": "2015-1-31"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.00064",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.00064",
        "title": "\nA Batchwise Monotone Algorithm for Dictionary Learning",
        "abstract": "We propose a batchwise monotone algorithm for dictionary learning. Unlike the state-of-the-art dictionary learning algorithms which impose sparsity constraints on a sample-by-sample basis, we instead treat the samples as a batch, and impose the sparsity constraint on the whole. The benefit of batchwise optimization is that the non-zeros can be better allocated across the samples, leading to a better approximation of the whole. To accomplish this, we propose procedures to switch non-zeros in both rows and columns in the support of the coefficient matrix to reduce the reconstruction error. We prove in the proposed support switching procedure the objective of the algorithm, i.e., the reconstruction error, decreases monotonically and converges. Furthermore, we introduce a block orthogonal matching pursuit algorithm that also operates on sample batches to provide a warm start. Experiments on both natural image patches and UCI data sets show that the proposed algorithm produces a better approximation with the same sparsity levels compared to the state-of-the-art algorithms.",
        "subjects": "Learning (cs.LG)",
        "authors": "Huan Wang, John Wright, Daniel Spielman,",
        "date": "2015-1-31"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.00065",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.00065",
        "title": "\nSequential Defense Against Random and Intentional Attacks in Complex  Networks",
        "abstract": "Network robustness against attacks is one of the most fundamental researches in network science as it is closely associated with the reliability and functionality of various networking paradigms. However, despite the study on intrinsic topological vulnerabilities to node removals, little is known on the network robustness when network defense mechanisms are implemented, especially for networked engineering systems equipped with detection capabilities. In this paper, a sequential defense mechanism is firstly proposed in complex networks for attack inference and vulnerability assessment, where the data fusion center sequentially infers the presence of an attack based on the binary attack status reported from the nodes in the network. The network robustness is evaluated in terms of the ability to identify the attack prior to network disruption under two major attack schemes, i.e., random and intentional attacks. We provide a parametric plug-in model for performance evaluation on the proposed mechanism and validate its effectiveness and reliability via canonical complex network models and real-world large-scale network topology. The results show that the sequential defense mechanism greatly improves the network robustness and mitigates the possibility of network disruption by acquiring limited attack status information from a small subset of nodes in the network.",
        "subjects": "Social and Information Networks (cs.SI)",
        "authors": "Pin-Yu Chen, Shin-Ming Cheng,",
        "date": "2015-1-31"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.00068",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.00068",
        "title": "\nTuPAQ: An Efficient Planner for Large-scale Predictive Analytic Queries",
        "abstract": "The proliferation of massive datasets combined with the development of sophisticated analytical techniques have enabled a wide variety of novel applications such as improved product recommendations, automatic image tagging, and improved speech-driven interfaces. These and many other applications can be supported by Predictive Analytic Queries (PAQs). A major obstacle to supporting PAQs is the challenging and expensive process of identifying and training an appropriate predictive model. Recent efforts aiming to automate this process have focused on single node implementations and have assumed that model training itself is a black box, thus limiting the effectiveness of such approaches on large-scale problems. In this work, we build upon these recent efforts and propose an integrated PAQ planning architecture that combines advanced model search techniques, bandit resource allocation via runtime algorithm introspection, and physical optimization via batching. The result is TuPAQ, a component of the MLbase system, which solves the PAQ planning problem with comparable quality to exhaustive strategies but an order of magnitude more efficiently than the standard baseline approach, and can scale to models trained on terabytes of data across hundreds of machines.",
        "subjects": "Databases (cs.DB)",
        "authors": "Evan R. Sparks, Ameet Talwalkar, Michael J. Franklin, Michael I. Jordan, Tim Kraska,",
        "date": "2015-1-1"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.00075",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.00075",
        "title": "\nByzantine Broadcast Under a Selective Broadcast Model for Single-hop  Wireless Networks",
        "abstract": "This paper explores an old problem, (BB), under a new model, . The new model \"interpolates\" between the two traditional models in the literature. In particular, it allows fault-free nodes to exploit the benefits of a broadcast channel (a feature from reliable broadcast model) and allows faulty nodes to send mismatching messages to different neighbors (a feature from point-to-point model) simultaneously. The model is motivated by the potential for transmissions on a wireless channel. We provide a collection of results for a single-hop wireless network under the new model. First, we present an algorithm for BB that is order-optimal in bit complexity. Then, we provide an algorithm that is designed to achieve BB efficiently in terms of message complexity. Third, we determine some lower bounds on both bit and message complexities of BB problems in the . Finally, we present a conjecture on an \"exact\" lower bound on the bit complexity of BB under the model.",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)",
        "authors": "Lewis Tseng, Nitin Vaidya,",
        "date": "2015-1-31"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.00076",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.00076",
        "title": "\nDesign of a Unified Transport Triggered Processor for LDPC/Turbo Decoder",
        "abstract": "This paper summarizes the design of a programmable processor with transport triggered architecture (TTA) for decoding LDPC and turbo codes. The processor architecture is designed in such a manner that it can be programmed for LDPC or turbo decoding for the purpose of internetworking and roaming between different networks. The standard trellis based maximum a posteriori (MAP) algorithm is used for turbo decoding. Unlike most other implementations, a supercode based sum-product algorithm is used for the check node message computation for LDPC decoding. This approach ensures the highest hardware utilization of the processor architecture for the two different algorithms. Up to our knowledge, this is the first attempt to design a TTA processor for the LDPC decoder. The processor is programmed with a high level language to meet the time-to-market requirement. The optimization techniques and the usage of the function units for both algorithms are explained in detail. The processor achieves 22.64 Mbps throughput for turbo decoding with a single iteration and 10.12 Mbps throughput for LDPC decoding with five iterations for a clock frequency of 200 MHz.",
        "subjects": "Information Theory (cs.IT)",
        "authors": "Shahriar Shahabuddin, Janne Janhunen, Muhammet Fatih Bayramoglu, Markku Juntti, Amanullah Ghazi, Olli Silven,",
        "date": "2015-1-31"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.00079",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.00079",
        "title": "\nEXIT Chart Analysis of Block Markov Superposition Transmission of Short  Codes",
        "abstract": "In this paper, a modified extrinsic information transfer (EXIT) chart analysis that takes into account the relation between mutual information (MI) and bit-error-rate (BER) is presented to study the convergence behavior of block Markov superposition transmission (BMST) of short codes (referred to as basic codes). We show that the threshold curve of BMST codes using an iterative sliding window decoding algorithm with a fixed decoding delay achieves a lower bound in the high signal-to-noise ratio (SNR) region, while in the low SNR region, due to error propagation, the thresholds of BMST codes become slightly worse as the encoding memory increases. We also demonstrate that the threshold results are consistent with finite-length performance simulations.",
        "subjects": "Information Theory (cs.IT)",
        "authors": "Kechao Huang, Xiao Ma, Daniel J. Costello Jr,",
        "date": "2015-1-31"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.00082",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.00082",
        "title": "\nCategory-Epitomes : Discriminatively Minimalist Representations for  Object Categories",
        "abstract": "Freehand line sketches are an interesting and unique form of visual representation. Typically, such sketches are studied and utilized as an end product of the sketching process. However, we have found it instructive to study the sketches as sequentially accumulated composition of drawing strokes added over time. Studying sketches in this manner has enabled us to create novel sparse yet discriminative sketch-based representations for object categories which we term category-epitomes. Our procedure for obtaining these epitomes concurrently provides a natural measure for quantifying the sparseness underlying the original sketch, which we term epitome-score. We construct and analyze category-epitomes and epitome-scores for freehand sketches belonging to various object categories. Our analysis provides a novel viewpoint for studying the semantic nature of object categories.",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "authors": "Ravi Kiran Sarvadevabhatla, R. Venkatesh Babu,",
        "date": "2015-1-31"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.00087",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.00087",
        "title": "\nOn Optimization of Network-coded Scalable Multimedia Service  Multicasting",
        "abstract": "In the near future, the delivery of multimedia multicast services over next-generation networks is likely to become one of the main pillars of future cellular networks. In this extended abstract, we address the issue of efficiently multicasting layered video services by defining a novel optimization paradigm that is based on an Unequal Error Protection implementation of Random Linear Network Coding, and aims to ensure target service coverages by using a limited amount of radio resources.",
        "subjects": "Information Theory (cs.IT)",
        "authors": "Andrea Tassi, Ioannis Chatzigeorgiou, Dejan Vukobratovi\u0107,",
        "date": "2015-1-31"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.00182",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.00182",
        "title": "\nHigh Dimensional Low Rank plus Sparse Matrix Decomposition",
        "abstract": "This paper is concerned with the problem of low rank plus sparse matrix decomposition for big data applications. Most of the existing decomposition algorithms are not applicable in high dimensional settings for two main reasons. First, they need the whole data to extract the low-rank/sparse components; second, they are based on an optimization problem whose dimensionality is equal to the dimension of the given data. In this paper, we present a randomized decomposition algorithm which exploits the low dimensional geometry of the low rank matrix to reduce the complexity. The low rank plus sparse matrix decomposition problem is reformulated as a columns-rows subspace learning problem. It is shown that when the columns/rows subspace of the low rank matrix is incoherent with the standard basis, the columns/rows subspace can be learned from a small random subset of the columns/rows of the given data matrix. Thus, the high dimensional decomposition problem is converted to a subspace learning problem (which is a low dimensional optimization problem) and it uses a small random subset of the data rather than the whole big data matrix. We derive sufficient conditions, which are no more stringent than those for existing methods, to ensure exact decomposition with high probability.",
        "subjects": "Numerical Analysis (cs.NA)",
        "authors": "Mostafa Rahmani, George Atia,",
        "date": "2015-2-1"
    },
    {
        "urllink": "http://arxiv.org/abs/1503.00202",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1503.00202",
        "title": "\nOn Integrating Information Visualization Techniques into Data Mining: A  Review",
        "abstract": "The exploding growth of digital data in the information era and its immeasurable potential value has called for different types of data-driven techniques to exploit its value for further applications. Information visualization and data mining are two research field with such goal. While the two communities advocates different approaches of problem solving, the vision of combining the sophisticated algorithmic techniques from data mining as well as the intuitivity and interactivity of information visualization is tempting. In this paper, we attempt to survey recent researches and real world systems integrating the wisdom in two fields towards more effective and efficient data analytics. More specifically, we study the intersection from a data mining point of view, explore how information visualization can be used to complement and improve different stages of data mining through established theories for optimized visual presentation as well as practical toolsets for rapid development. We organize the survey by identifying three main stages of typical process of data mining, the preliminary analysis of data, the model construction, as well as the model evaluation, and study how each stage can benefit from information visualization.",
        "subjects": "Graphics (cs.GR)",
        "authors": "Keqian Li,",
        "date": "2015-3-1"
    },
    {
        "urllink": "http://arxiv.org/abs/1503.00477",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1503.00477",
        "title": "\nBehavioral Aspects of Social Network Analysis",
        "abstract": "Contrary to the structural aspect of conventional social network analysis, a new method in behavioral analysis is proposed. We define behavioral measures including self-loops and multiple links and illustrate the behavioral analysis with the networks of Wikipedia editing. Behavioral social network analysis provides an explanation of human behavior that may be further extended to the explanation of culture through social phenomena.",
        "subjects": "Social and Information Networks (cs.SI)",
        "authors": "Sung Joo Park, Jong Woo Kim, Hong Joo Lee, Hyun Jung Park, Peter Gloor,",
        "date": "2015-3-2"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.00092",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.00092",
        "title": "\nImage Super-Resolution Using Deep Convolutional Networks",
        "abstract": "We propose a deep learning method for single image super-resolution (SR). Our method directly learns an end-to-end mapping between the low/high-resolution images. The mapping is represented as a deep convolutional neural network (CNN) that takes the low-resolution image as the input and outputs the high-resolution one. We further show that traditional sparse-coding-based SR methods can also be viewed as a deep convolutional network. But unlike traditional methods that handle each component separately, our method jointly optimizes all layers. Our deep CNN has a lightweight structure, yet demonstrates state-of-the-art restoration quality, and achieves fast speed for practical on-line usage. We explore different network structures and parameter settings to achieve trade-offs between performance and speed. Moreover, we extend our network to cope with three color channels simultaneously, and show better overall reconstruction quality.",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "authors": "Chao Dong, Chen Change Loy, Kaiming He, Xiaoou Tang,",
        "date": "2014-12-31"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.00386",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.00386",
        "title": "\nComputability on the countable ordinals and the Hausdorff-Kuratowski  theorem",
        "abstract": "In this note, we explore various potential representations of the set of countable ordinals. An equivalence class of representations is then suggested as a standard, as it offers the desired closure properties. With a decent notion of computability on the space of countable ordinals in place, we can then state and prove a computable uniform version of the Hausdorff-Kuratowski theorem.",
        "subjects": "Logic in Computer Science (cs.LO)",
        "authors": "Arno Pauly,",
        "date": "2015-1-2"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.00687",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.00687",
        "title": "\nOn Enhancing The Performance Of Nearest Neighbour Classifiers Using  Hassanat Distance Metric",
        "abstract": "We showed in this work how the Hassanat distance metric enhances the performance of the nearest neighbour classifiers. The results demonstrate the superiority of this distance metric over the traditional and most-used distances, such as Manhattan distance and Euclidian distance. Moreover, we proved that the Hassanat distance metric is invariant to data scale, noise and outliers. Throughout this work, it is clearly notable that both ENN and IINC performed very well with the distance investigated, as their accuracy increased significantly by 3.3% and 3.1% respectively, with no significant advantage of the ENN over the IINC in terms of accuracy. Correspondingly, it can be noted from our results that there is no optimal algorithm that can solve all real-life problems perfectly; this is supported by the no-free-lunch theorem",
        "subjects": "Learning (cs.LG)",
        "authors": "Mouhammd Alkasassbeh, Ghada A. Altarawneh, Ahmad B. A. Hassanat,",
        "date": "2015-1-4"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.01090",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.01090",
        "title": "\nA Novel Technique for Grading of Dates using Shape and Texture Features",
        "abstract": "This paper presents a novel method to grade the date fruits based on the combination of shape and texture features. The method begins with reducing the specular reflection and small noise using a bilateral filter. Threshold based segmentation is performed for background removal and fruit part selection from the given image. Shape features is extracted using the contour of the date fruit and texture features are extracted using Curvelet transform and Local Binary Pattern (LBP) from the selected date fruit region. Finally, combinations of shape and texture features are fused to grade the dates into six grades. k-Nearest Neighbour(k-NN) classifier yields the best grading rate compared to other two classifiers such as Support Vector Machine (SVM) and Linear Discriminant(LDA) classifiers. The experiment result shows that our technique achieves highest accuracy.",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "authors": "S.H. Mohana, C.J. Prabhakar,",
        "date": "2015-1-6"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.01372",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.01372",
        "title": "\nWeighted Schatten $p$-Norm Minimization for Image Denoising with Local  and Nonlocal Regularization",
        "abstract": "This paper presents a patch-wise low-rank based image denoising method with constrained variational model involving local and nonlocal regularization. On one hand, recent patch-wise methods can be represented as a low-rank matrix approximation problem whose convex relaxation usually depends on nuclear norm minimization (NNM). Here, we extend the NNM to the nonconvex schatten p-norm minimization with additional weights assigned to different singular values, which is referred to as the Weighted Schatten p-Norm Minimization (WSNM). An efficient algorithm is also proposed to solve the WSNM problem. The proposed WSNM not only gives better approximation to the original low-rank assumption, but also considers physical meanings of different data components. On the other hand, due to the naive aggregation schema which integrates all the denoised patches into a whole image, current patch-wise denoising methods always produce various degree of artifacts in denoised results. Therefore, to further reduce artifacts, a data-driven regularizer called Steering Total Variation (STV) combined with nonlocal TV is derived for a variational model, which imposes local and nonlocal consistency constraints on the patch-wise denoised image. A highly simple but efficient algorithm is proposed to solve this variational model with convergence guarantee. Both WSNM and local &amp; nonlocal consistent regularization are integrated into an iterative restoration framework to produce final results. Extensive experimental testing shows, both qualitatively and quantitatively, that the proposed method can effectively remove noise, as well as reduce artifacts compared with state-of-the-art methods.",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV)",
        "authors": "Yuan Xie,",
        "date": "2015-1-7"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.01696",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.01696",
        "title": "\nOn the Complexity of Sorted Neighborhood",
        "abstract": "Record linkage concerns identifying semantically equivalent records in databases. Blocking methods are employed to avoid the cost of full pairwise similarity comparisons on records. In a seminal work, Hernandez and Stolfo proposed the Sorted Neighborhood blocking method. Several empirical variants have been proposed in recent years. In this paper, we investigate the complexity of the Sorted Neighborhood procedure on which the variants are built. We show that achieving maximum performance on the Sorted Neighborhood procedure entails solving a sub-problem, which is shown to be NP-complete by reducing from the Travelling Salesman Problem. We also show that the sub-problem can occur in the traditional blocking method. Finally, we draw on recent developments concerning approximate Travelling Salesman solutions to define and analyze three approximation algorithms.",
        "subjects": "Computational Complexity (cs.CC)",
        "authors": "Mayank Kejriwal, Daniel P. Miranker,",
        "date": "2015-1-8"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.01909",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.01909",
        "title": "\nZ-score-based modularity for community detection in networks",
        "abstract": "Identifying community structure in networks is an issue of particular interest in network science. The modularity introduced by Newman and Girvan [Phys. Rev. E 69, 026113 (2004)] is the most popular quality function for community detection in networks. In this study, we identify a problem in the concept of modularity and suggest a solution to overcome this problem. Specifically, we obtain a new quality function for community detection. We refer to the function as Z-modularity because it measures the Z-score of a given division with respect to the fraction of the number of edges within communities. Our theoretical analysis shows that Z-modularity mitigates the resolution limit of the original modularity in certain cases. Computational experiments using both artificial networks and well-known real-world networks demonstrate the validity and reliability of the proposed quality function.",
        "subjects": "Social and Information Networks (cs.SI)",
        "authors": "Atsushi Miyauchi, Yasushi Kawase,",
        "date": "2015-1-8"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.02134",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.02134",
        "title": "\nFinding Volunteers' Engagement Profiles in Human Computation for Citizen  Science Projects",
        "abstract": "Human computation is a computing approach that draws upon human cognitive abilities to solve computational tasks for which there are so far no satisfactory fully automated solutions even when using the most advanced computing technologies available. Human computation for citizen science projects consists in designing systems that allow large crowds of volunteers to contribute to scientific research by executing human computation tasks. Examples of successful projects are Galaxy Zoo and FoldIt. A key feature of this kind of project is its capacity to engage volunteers. An important requirement for the proposal and evaluation of new engagement strategies is having a clear understanding of the typical engagement of the volunteers; however, even though several projects of this kind have already been completed, little is known about this issue. In this paper, we investigate the engagement pattern of the volunteers in their interactions in human computation for citizen science projects, how they differ among themselves in terms of engagement, and how those volunteer engagement features should be taken into account for establishing the engagement encouragement strategies that should be brought into play in a given project. To this end, we define four quantitative engagement metrics to measure different aspects of volunteer engagement, and use data mining algorithms to identify the different volunteer profiles in terms of the engagement metrics. Our study is based on data collected from two projects: Galaxy Zoo and The Milky Way Project. The results show that the volunteers in such projects can be grouped into five distinct engagement profiles that we label as follows: hardworking, spasmodic, persistent, lasting, and moderate. The analysis of these profiles provides a deeper understanding of the nature of volunteers' engagement in human computation for citizen science projects",
        "subjects": "Human-Computer Interaction (cs.HC)",
        "authors": "Lesandro Ponciano, Francisco Brasileiro,",
        "date": "2015-1-9"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.02429",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.02429",
        "title": "\nEnhancing Wireless Information and Power Transfer by Exploiting  Multi-Antenna Techniques",
        "abstract": "This paper reviews emerging wireless information and power transfer (WIPT) technique with an emphasis on its performance enhancement employing multi-antenna techniques. Compared to traditional wireless information transmission, WIPT faces numerous challenges. First, it is more susceptible to channel fading and path loss, resulting in a much shorter power transfer distance. Second, it gives rise to the issue on how to balance spectral efficiency for information transmission and energy efficiency for power transfer in order to obtain an optimal tradeoff. Third, there exists a security issue for information transmission in order to improve power transfer efficiency. In this context, multi-antenna techniques, e.g., energy beamforming, are introduced to solve these problems by exploiting spatial degree of freedom. This article provides a tutorial on various aspects of multi-antenna based WIPT techniques, with a focus on tackling the challenges by parameter optimization and protocol design. In particular, we investigate the WIPT tradeoffs based on two typical multi-antenna techniques, namely limited feedback multi-antenna technique for short-distance transfer and large-scale multiple-input multiple-output (LS-MIMO, also known as massive MIMO) technique for long-distance transfer. Finally, simulation results validate the effectiveness of the proposed schemes.",
        "subjects": "Information Theory (cs.IT)",
        "authors": "Xiaoming Chen, Zhaoyang Zhang, Hsiao-Hwa Chen, Huazi Zhang,",
        "date": "2015-1-11"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.02702",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.02702",
        "title": "\nMax-Cost Discrete Function Evaluation Problem under a Budget",
        "abstract": "We propose novel methods for max-cost Discrete Function Evaluation Problem (DFEP) under budget constraints. We are motivated by applications such as clinical diagnosis where a patient is subjected to a sequence of (possibly expensive) tests before a decision is made. Our goal is to develop strategies for minimizing max-costs. The problem is known to be NP hard and greedy methods based on specialized impurity functions have been proposed. We develop a broad class of emph impurity functions that admit monomials, classes of polynomials, and hinge-loss functions that allow for flexible impurity design with provably optimal approximation bounds. This flexibility is important for datasets when max-cost can be overly sensitive to \"outliers.\" Outliers bias max-cost to a few examples that require a large number of tests for classification. We design admissible functions that allow for accuracy-cost trade-off and result in guarantees of the optimal cost among trees with corresponding classification accuracy levels.",
        "subjects": "Learning (cs.LG)",
        "authors": "Feng Nan, Joseph Wang, Venkatesh Saligrama,",
        "date": "2015-1-12"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.03084",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.03084",
        "title": "\nDeep Learning with Nonparametric Clustering",
        "abstract": "Clustering is an essential problem in machine learning and data mining. One vital factor that impacts clustering performance is how to learn or design the data representation (or features). Fortunately, recent advances in deep learning can learn unsupervised features effectively, and have yielded state of the art performance in many classification problems, such as character recognition, object recognition and document categorization. However, little attention has been paid to the potential of deep learning for unsupervised clustering problems. In this paper, we propose a deep belief network with nonparametric clustering. As an unsupervised method, our model first leverages the advantages of deep learning for feature representation and dimension reduction. Then, it performs nonparametric clustering under a maximum margin framework -- a discriminative clustering model and can be trained online efficiently in the code space. Lastly model parameters are refined in the deep belief network. Thus, this model can learn features for clustering and infer model complexity in an unified framework. The experimental results show the advantage of our approach over competitive baselines.",
        "subjects": "Learning (cs.LG)",
        "authors": "Gang Chen,",
        "date": "2015-1-13"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.03566",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.03566",
        "title": "\nOn a Conjecture of Erd{\u0151}s, Frankl and F{\u00fc}redi",
        "abstract": "Let be an -element set. Assume is a collection of subsets of . We call an -cover-free family if holds for all distinct . Given , denote the minimal such that there exits an -cover-free family on an -element set with cardinality larger than . Thirty years ago, Erd Hs, Frankl and Fredi cite proved that . They also conjectured and claimed that , without proof. In this paper, it is proved that , which is a quantity in . In particular, their conjecture is proved to be true for all r-cover-free families with uniform -subsets.",
        "subjects": "Information Theory (cs.IT)",
        "authors": "Gennian Ge, Chong Shangguan,",
        "date": "2015-1-15"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.03895",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.03895",
        "title": "\nRoot-Weighted Tree Automata and their Applications to Tree Kernels",
        "abstract": "In this paper, we define a new kind of weighted tree automata where the weights are only supported by final states. We show that these automata are sequentializable and we study their closures under classical regular and algebraic operations. We then use these automata to compute the subtree kernel of two finite tree languages in an efficient way. Finally, we present some perspectives involving the root-weighted tree automata.",
        "subjects": "Formal Languages and Automata Theory (cs.FL)",
        "authors": "Ludovic Mignot, Nadia Ouali-Sebti, Djelloul Ziadi,",
        "date": "2015-1-16"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.04232",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.04232",
        "title": "\nMaximum Entropy Models of Shortest Path and Outbreak Distributions in  Networks",
        "abstract": "Properties of networks are often characterized in terms of features such as node degree distributions, average path lengths, diameters, or clustering coefficients. Here, we study shortest path length distributions. On the one hand, average as well as maximum distances can be determined therefrom; on the other hand, they are closely related to the dynamics of network spreading processes. Because of the combinatorial nature of networks, we apply maximum entropy arguments to derive a general, physically plausible model. In particular, we establish the generalized Gamma distribution as a continuous characterization of shortest path length histograms of networks or arbitrary topology. Experimental evaluations corroborate our theoretical results.",
        "subjects": "Social and Information Networks (cs.SI)",
        "authors": "Christian Bauckhage, Kristian Kersting, Fabian Hadiji,",
        "date": "2015-1-17"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.04478",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.04478",
        "title": "\nInformation Leakage of Heterogeneous Encoded Correlated Sequences over  Eavesdropped Channel",
        "abstract": "Correlated sources are present in communication systems where protocols ensure that there is some predetermined information for sources. Here correlated sources across an eavesdropped channel that incorporate a heterogeneous encoding scheme and their effect on the information leakage when some channel information and a source have been wiretapped is investigated. The information leakage bounds for the Slepian-Wolf scenario are provided. Thereafter, the Shannon cipher system approach is presented. Further, an implementation method using a matrix partition approach is described.",
        "subjects": "Information Theory (cs.IT)",
        "authors": "R Balmahoon, L Cheng,",
        "date": "2015-1-9"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.04719",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.04719",
        "title": "\nStability of Surface Contacts for Humanoid Robots: Closed-Form Formulae  of the Contact Wrench Cone for Rectangular Support Areas",
        "abstract": "Humanoid robots locomote by making and breaking contacts with their environment. A crucial problem is therefore to find precise criteria for a given contact to remain stable or to break. For rigid surface contacts, the most general criterion is the Contact Wrench Condition (CWC). To check whether a motion satisfies the CWC, existing approaches take into account a large number of individual contact forces (for instance, one at each vertex of the support polygon), which is computationally costly and prevents the use of efficient inverse-dynamics methods. Here we argue that the CWC can be explicitly computed without reference to individual contact forces, and give closed-form formulae in the case of rectangular surfaces -- which is of practical importance. It turns out that these formulae simply and naturally express three conditions: (i) Coulomb friction on the resultant force, (ii) ZMP inside the support area, and (iii) bounds on the yaw torque. Conditions (i) and (ii) are already known, but condition (iii) is, to the best of our knowledge, novel. It is also of particular interest for biped locomotion, where undesired foot yaw rotations are a known issue. We also show that our formulae yield simpler and faster computations than existing approaches for humanoid motions in single support, and demonstrate their consistency in the OpenHRP simulator.",
        "subjects": "Robotics (cs.RO)",
        "authors": "St\u00e9phane Caron, Quang-Cuong Pham, Yoshihiko Nakamura,",
        "date": "2015-1-20"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.05279",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.05279",
        "title": "\nExtreme Entropy Machines: Robust information theoretic classification",
        "abstract": "Most of the existing classification methods are aimed at minimization of empirical risk (through some simple point-based error measured with loss function) with added regularization. We propose to approach this problem in a more information theoretic way by investigating applicability of entropy measures as a classification model objective function. We focus on quadratic Renyi's entropy and connected Cauchy-Schwarz Divergence which leads to the construction of Extreme Entropy Machines (EEM). The main contribution of this paper is proposing a model based on the information theoretic concepts which on the one hand shows new, entropic perspective on known linear classifiers and on the other leads to a construction of very robust method competetitive with the state of the art non-information theoretic ones (including Support Vector Machines and Extreme Learning Machines). Evaluation on numerous problems spanning from small, simple ones from UCI repository to the large (hundreads of thousands of samples) extremely unbalanced (up to 100:1 classes' ratios) datasets shows wide applicability of the EEM in real life problems and that it scales well.",
        "subjects": "Learning (cs.LG)",
        "authors": "Wojciech Marian Czarnecki, Jacek Tabor,",
        "date": "2015-1-21"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.05578",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.05578",
        "title": "\nA Model of an E-Learning Web Site for Teaching and Evaluating Online",
        "abstract": "This research is endeavoring to design an e-learning web site on the internet having the course name as \"Object Oriented Programming\" (OOP) for the students of level four at Computer Science Department (CSD). This course is to be taught online (through web) and then a programme is to be designed to evaluate students performance electronically while introducing a comparison between online teaching , e-evaluation and traditional methods of evaluation. The research seeks to lay out a futuristic perception that how the future online teaching and e-electronic evaluation should be the matter which highlights the importance of this research.",
        "subjects": "Computers and Society (cs.CY)",
        "authors": "Mohammed A. Amasha, Salem Alkhalaf,",
        "date": "2015-1-22"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.05614",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.05614",
        "title": "\nInt{\u00e9}gration d'une mesure d'ind{\u00e9}pendance pour la fusion  d'informations",
        "abstract": "Many information sources are considered into data fusion in order to improve the decision in terms of uncertainty and imprecision. For each technique used for data fusion, the asumption on independance is usually made. We propose in this article an approach to take into acount an independance measure befor to make the combination of information in the context of the theory of belief functions.",
        "subjects": "Artificial Intelligence (cs.AI)",
        "authors": "Mouloud Kharoune, Arnaud Martin,",
        "date": "2015-1-22"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.05902",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.05902",
        "title": "\nSliding window-based Contention Resolution Diversity Slotted ALOHA",
        "abstract": "Contention Resolution Diversity Slotted ALOHA (CRDSA) and its burst degree optimizations (CRDSA++, IRSA) make use of MAC burst repetitions and Interference Cancellation (IC) making possible to reach throughput values as high as in practical implementations, whereas for the traditional slotted ALOHA . However, these new techniques introduce a frame-based access to the channel that limits the performance in terms of throughput and packet delivery delay. In this paper, a new technique named Sliding Window CRDSA (SW-CRDSA) and its counterpart for irregular repetitions (SW-IRSA) are introduced in order to exploit the advantages of MAC burst repetition and Interference Cancellation (IC) with an unframed access scheme. Numerical results are also provided in order to validate the statement of better performance.",
        "subjects": "Information Theory (cs.IT)",
        "authors": "Alessio Meloni, Maurizio Murroni, Christian Kissling, Matteo Berioli,",
        "date": "2015-1-23"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.06158",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.06158",
        "title": "\nTSP with Time Windows and Service Time",
        "abstract": "We consider TSP with time windows and service time. In this problem we receive a sequence of requests for a service at nodes in a metric space and a time window for each request. The goal of the online algorithm is to maximize the number of requests served during their time window. The time to traverse an edge is the distance between the incident nodes of that edge. Serving a request requires unit time. We characterize the competitive ratio for each metric space separately. The competitive ratio depends on the relation between the minimum laxity (the minimum length of a time window) and the diameter of the metric space. Specifically, there is a constant competitive algorithm depending whether the laxity is larger or smaller than the diameter. In addition, we characterize the rate of convergence of the competitive ratio to as the laxity increases. Specifically, we provide a matching lower and upper bounds depending on the ratio between the laxity and the TSP of the metric space (the minimum distance to traverse all nodes). An application of our result improves the lower bound for colored packets with transition cost and matches the upper bound. In proving our lower bounds we use an interesting non-standard embedding with some special properties. This embedding may be interesting by its own.",
        "subjects": "Data Structures and Algorithms (cs.DS)",
        "authors": "Yossi Azar, Adi Vardi,",
        "date": "2015-1-25"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.06446",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.06446",
        "title": "\nIndex Policies for Optimal Mean-Variance Trade-Off of Inter-delivery  Times in Real-Time Sensor Networks",
        "abstract": "A problem of much current practical interest is the replacement of the wiring infrastructure connecting approximately 200 sensor and actuator nodes in automobiles by an access point. This is motivated by the considerable savings in automobile weight, simplification of manufacturability, and future upgradability. A key issue is how to schedule the nodes on the shared access point so as to provide regular packet delivery. In this and other similar applications, the mean of the inter-delivery times of packets, i.e., throughput, is not sufficient to guarantee service-regularity. The time-averaged variance of the inter-delivery times of packets is also an important metric. So motivated, we consider a wireless network where an Access Point schedules real-time generated packets to nodes over a fading wireless channel. We are interested in designing simple policies which achieve optimal mean-variance tradeoff in interdelivery times of packets by minimizing the sum of time-averaged means and variances over all clients. Our goal is to explore the full range of the Pareto frontier of all weighted linear combinations of mean and variance so that one can fully exploit the design possibilities. We transform this problem into a Markov decision process and show that the problem of choosing which node's packet to transmit in each slot can be formulated as a bandit problem. We establish that this problem is indexable and explicitly derive the Whittle indices. The resulting Index policy is optimal in certain cases. We also provide upper and lower bounds on the cost for any policy. Extensive simulations show that Index policies perform better than previously proposed policies.",
        "subjects": "Networking and Internet Architecture (cs.NI)",
        "authors": "Rahul Singh, Xueying Guo, P.R. Kumar,",
        "date": "2015-1-26"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.06862",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.06862",
        "title": "\nFactorization of Rational Motions: A Survey with Examples and  Applications",
        "abstract": "Since its introduction in 2012, the factorization theory for rational motions quickly evolved and found applications in theoretical and applied mechanism science. We provide an accessible introduction to motion factorization with many examples, summarize recent developments and hint at some new applications. In particular, we provide pseudo-code for the generic factorization algorithm, demonstrate how to find a replacement linkage for a special case in the synthesis of Bennett mechanisms and, as an example of non-generic factorization, synthesize open chains for circular and elliptic translations.",
        "subjects": "Robotics (cs.RO)",
        "authors": "Zijia Li, Tudor-Dan Rad, Josef Schicho, Hans-Peter Schr\u00f6cker,",
        "date": "2015-1-27"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.07080",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.07080",
        "title": "\nOn the genetic optimization of APSK constellations for satellite  broadcasting",
        "abstract": "Both satellite transmissions and DVB applications over satellite present peculiar characteristics that could be taken into consideration in order to further exploit the optimality of the transmission. In this paper, starting from the state-of-the-art, the optimization of the APSK constellation through asymmetric symbols arrangement is investigated for its use in satellite communications. In particular, the optimization problem is tackled by means of Genetic Algorithms that have already been demonstrated to work nicely with complex non-linear optimization problems like the one presented hereinafter. This work aims at studying the various parameters involved in the optimization routine in order to establish those that best fit this case, thus further enhancing the constellation.",
        "subjects": "Information Theory (cs.IT)",
        "authors": "Alessio Meloni, Maurizio Murroni,",
        "date": "2015-1-28"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.07348",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.07348",
        "title": "\nFinding Connected Dense $k$-Subgraphs",
        "abstract": "Given a connected graph on vertices and a positive integer , a subgraph of on vertices is called a -subgraph in . We design combinatorial approximation algorithms for finding a connected -subgraph in such that its density is at least a factor of the density of the densest -subgraph in (which is not necessarily connected). These particularly provide the first non-trivial approximations for the densest connected -subgraph problem on general graphs.",
        "subjects": "Discrete Mathematics (cs.DM)",
        "authors": "Xujin Chen, Xiaodong Hu, Changjun Wang,",
        "date": "2015-1-29"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.07695",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.07695",
        "title": "\nLive Group Detection for Mobile Wireless Sensor Networks",
        "abstract": "This paper deals with distributed algorithms for monitoring the topology of a dynamic group of mobile wireless sensor networks. We propose two major extensions of a distributed static group consensus algorithm and an experimental implementation. Group consensus algorithms are exploited to let each node obtain the knowledge of its connected com-ponents. The proposed extensions provide a more accurate information about the proximity of nodes and allow to deal with dynamic networks using a periodical reevaluation of the group detection. We validate these algorithms by implementing them in an original and challenging application scenario, in the context of a real bicycle race. The real traces thus obtained and analyzed show the effectiveness of our live group detection implementation.",
        "subjects": "Networking and Internet Architecture (cs.NI)",
        "authors": "Matthieu Lauzier, Tanguy Risset, Antoine Fraboulet, Jean-Marie Gorce,",
        "date": "2015-1-30"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.00379",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.00379",
        "title": "\nThe number of unit-area triangles in the plane: Theme and variations",
        "abstract": "We show that the number of unit-area triangles determined by a set of points in the plane is , improving the earlier bound of Apfelbaum and Sharir [Discrete Comput. Geom., 2010]. We also consider two special cases of this problem: (i) We show, using a somewhat subtle construction, that if consists of points on three lines, the number of unit-area triangles that spans, with one vertex on each of the lines, can be , for any triple of lines (this number is always in this case). (ii) We show that if is a of the form , where , are sets of real numbers each (i.e., the sequences of differences of consecutive elements of and of are both strictly increasing), then determines unit-area triangles.",
        "subjects": "Combinatorics (math.CO)",
        "authors": "Orit E. Raz, Micha Sharir,",
        "date": "2015-1-2"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.03002",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.03002",
        "title": "\nAn Improvement to the Domain Adaptation Bound in a PAC-Bayesian context",
        "abstract": "This paper provides a theoretical analysis of domain adaptation based on the PAC-Bayesian theory. We propose an improvement of the previous domain adaptation bound obtained by Germain et al. in two ways. We first give another generalization bound tighter and easier to interpret. Moreover, we provide a new analysis of the constant term appearing in the bound that can be of high interest for developing new algorithmic solutions.",
        "subjects": "Machine Learning (stat.ML)",
        "authors": "Pascal Germain, Amaury Habrard, Francois Laviolette, Emilie Morvant,",
        "date": "2015-1-13"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.05684",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.05684",
        "title": "\nBi-Objective Nonnegative Matrix Factorization: Linear Versus  Kernel-Based Models",
        "abstract": "Nonnegative matrix factorization (NMF) is a powerful class of feature extraction techniques that has been successfully applied in many fields, namely in signal and image processing. Current NMF techniques have been limited to a single-objective problem in either its linear or nonlinear kernel-based formulation. In this paper, we propose to revisit the NMF as a multi-objective problem, in particular a bi-objective one, where the objective functions defined in both input and feature spaces are taken into account. By taking the advantage of the sum-weighted method from the literature of multi-objective optimization, the proposed bi-objective NMF determines a set of nondominated, Pareto optimal, solutions instead of a single optimal decomposition. Moreover, the corresponding Pareto front is studied and approximated. Experimental results on unmixing real hyperspectral images confirm the efficiency of the proposed bi-objective NMF compared with the state-of-the-art methods.",
        "subjects": "Machine Learning (stat.ML)",
        "authors": "Paul Honeine, Fei Zhu,",
        "date": "2015-1-22"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.02558",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.02558",
        "title": "\nK2-ABC: Approximate Bayesian Computation with Infinite Dimensional  Summary Statistics via Kernel Embeddings",
        "abstract": "Complicated generative models often result in a situation where computing the likelihood of observed data is intractable, while simulating from the conditional density given a parameter value is relatively easy. Approximate Bayesian Computation (ABC) is a paradigm that enables simulation-based posterior inference in such cases by measuring the similarity between simulated and observed data in terms of a chosen set of summary statistics. However, there is no general rule to construct sufficient summary statistics for complex models. Insufficient summary statistics will \"leak\" information, which leads to ABC algorithms yielding samples from an incorrect (partial) posterior. In this paper, we propose a fully nonparametric ABC paradigm which circumvents the need for manually selecting summary statistics. Our approach, K2-ABC, uses maximum mean discrepancy (MMD) as a dissimilarity measure between the distributions over observed and simulated data. MMD is easily estimated as the squared difference between their empirical kernel embeddings. Experiments on a simulated scenario and a real-world biological problem illustrate the effectiveness of the proposed algorithm.",
        "subjects": "Machine Learning (stat.ML)",
        "authors": "Mijung Park, Wittawat Jitkrittum, Dino Sejdinovic,",
        "date": "2015-2-9"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.08053",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.08053",
        "title": "\nStochastic Dual Coordinate Ascent with Adaptive Probabilities",
        "abstract": "This paper introduces AdaSDCA: an adaptive variant of stochastic dual coordinate ascent (SDCA) for solving the regularized empirical risk minimization problems. Our modification consists in allowing the method adaptively change the probability distribution over the dual variables throughout the iterative process. AdaSDCA achieves provably better complexity bound than SDCA with the best fixed probability distribution, known as importance sampling. However, it is of a theoretical character as it is expensive to implement. We also propose AdaSDCA+: a practical variant which in our experiments outperforms existing non-adaptive methods.",
        "subjects": "Optimization and Control (math.OC)",
        "authors": "Dominik Csiba, Zheng Qu, Peter Richt\u00e1rik,",
        "date": "2015-2-27"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.08029",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.08029",
        "title": "\nVideo Description Generation Incorporating Spatio-Temporal Features and  a Soft-Attention Mechanism",
        "abstract": "Recent progress in using recurrent neural networks (RNNs) for image description has motivated us to explore the application of RNNs to video description. Recent work has also suggested that attention mechanisms may be able to increase performance. To this end, we apply a long short-term memory (LSTM) network in two configurations: with a recently introduced soft-attention mechanism, and without. Our results suggest two things. First, incorporating a soft-attention mechanism into the text generation RNN significantly improves the quality of the descriptions. Second, using a combination of still frame features and dynamic motion-based features can also help. Ultimately, our combined approach exceeds the state-of-art on both BLEU and Meteor on the Youtube2Text dataset. We also present results on a new, larger and more complex dataset of paired video and natural language descriptions based on the use of Descriptive Video Service (DVS) annotations which are now widely available as an additional audio track on many DVDs.",
        "subjects": "Machine Learning (stat.ML)",
        "authors": "Li Yao, Atousa Torabi, Kyunghyun Cho, Nicolas Ballas, Christopher Pal, Hugo Larochelle, Aaron Courville,",
        "date": "2015-2-7"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.08014",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.08014",
        "title": "\nLocalization theorems for eigenvalues of quaternionic matrices",
        "abstract": "Ostrowski type and Brauer type theorems are derived for the left eigenvalues of quaternionic matrix. We see that the above theorems for the left eigenvalues are also true for the case of right eigenvalues, when the diagonals of quaternionic matrix are real. Some distribution theorems are given in terms of ovals of Cassini that are sharper than the Ostrowski type theorems, respectively, for the left and right eigenvalues of quaternionic matrix. In addition, generalizations of the Gerschgorin type theorems are discussed for both the left and right eigenvalues of quaternionic matrix, and finally, we see that our framework is so developed that generalizes the existing results in the literatures.",
        "subjects": "Rings and Algebras (math.RA)",
        "authors": "Sk. Safique Ahmad, Istkhar Ali,",
        "date": "2015-1-7"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.08003",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.08003",
        "title": "\nIllusory Sense of Human Touch from a Warm and Soft Artificial Hand",
        "abstract": "To touch and be touched are vital to human development, well being, and relationships. However, to those who have lost their arms and hands due to accident or war, touching becomes a serious concern that often leads to psychosocial issues and social stigma. In this paper, we demonstrate that the touch from a warm and soft rubber hand can be perceived by another person as if the touch were coming from a human hand. We describe a three step process toward this goal. First, we made participants select artificial skin samples according to their preferred warmth and softness characteristics. At room temperature, the preferred warmth was found to be 28.4 deg C at the skin surface of a soft silicone rubber material that has a Shore durometer value of 30 at the OO scale. Second, we developed a process to create a rubber hand replica of a human hand. To compare the skin softness of a human hand and artificial hands, a robotic indenter was employed to produce a softness map by recording the displacement data when constant indentation force of 1 N was applied to 780 data points on the palmar side of the hand. Results showed that an artificial hand with skeletal structure is as soft as a human hand. Lastly, the participants arms were touched with human and artificial hands, but they were prevented to see the hand that touched them. Receiver operating characteristic curve analysis suggests that a warm and soft artificial hand can create an illusion that the touch is from a human hand. These findings open the possibilities for prosthetic and robotic hands that are lifelike and are more socially acceptable.",
        "subjects": "Medical Physics (physics.med-ph)",
        "authors": "John-John Cabibihan, Deepak Joshi, Yeshwin Mysore Srinivasa, Mark Aaron Chan, Arrchana Muruganantham,",
        "date": "2015-2-27"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.07981",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.07981",
        "title": "\nThe lamplighter group $\\mathbb{Z}_3\\wr\\mathbb{Z}$ generated by a  bireversible automaton",
        "abstract": "We construct a bireversible self-dual automaton with states over an alphabet with letters which generates the lamplighter group .",
        "subjects": "Group Theory (math.GR)",
        "authors": "I. Bondarenko, D. D'Angeli, E. Rodaro,",
        "date": "2015-2-27"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.07977",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.07977",
        "title": "\nR\u00e9nyi generalizations of quantum information measures",
        "abstract": "Quantum information measures such as the entropy and the mutual information find applications in physics, e.g., as correlation measures. Generalizing such measures based on the R 'enyi entropies is expected to enhance their scope in applications. We prescribe R 'enyi generalizations for any quantum information measure which consists of a linear combination of von Neumann entropies with coefficients chosen from the set . As examples, we describe R 'enyi generalizations of the conditional quantum mutual information, some quantum multipartite information measures, and the topological entanglement entropy. Among these, we discuss the various properties of the R 'enyi conditional quantum mutual information and sketch some potential applications. We conjecture that the proposed R 'enyi conditional quantum mutual informations are monotone increasing in the R 'enyi parameter, and we have proofs of this conjecture for some special cases.",
        "subjects": "Quantum Physics (quant-ph)",
        "authors": "Mario Berta, Kaushik P. Seshadreesan, Mark M. Wilde,",
        "date": "2015-2-27"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.07973",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.07973",
        "title": "\nThe Fidelity of Recovery is Multiplicative",
        "abstract": "Fawzi and Renner (arXiv:1410.0664) recently established a lower bound on the conditional quantum mutual information of tripartite quantum states in terms of the fidelity of recovery, i.e. the maximal fidelity of the state with a state reconstructed from its marginal by acting only on the system. In this brief note we show that the fidelity of recovery is multiplicative by utilizing semi-definite programming duality. This allows us to simplify an operational proof by Brandao et al. (arXiv:1411.4921) of the above-mentioned lower bound that is based on quantum state redistribution. In particular, in contrast to the previous approaches, our proof does not rely on de Finetti reductions.",
        "subjects": "Quantum Physics (quant-ph)",
        "authors": "Mario Berta, Marco Tomamichel,",
        "date": "2015-2-27"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.07971",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.07971",
        "title": "\nA simple framework on sorting permutations",
        "abstract": "In this paper we present a simple framework to study various distance problems of permutations, including the transposition and block-interchange distance of permutations as well as the reversal distance of signed permutations. These problems are very important in the study of the evolution of genomes. We give a general formulation for lower bounds of the transposition and block-interchange distance from which the existing lower bounds obtained by Bafna and Pevzner, and Christie can be easily derived. As to the reversal distance of signed permutations, we translate it into a block-interchange distance problem of permutations so that we obtain a new lower bound. Furthermore, studying distance problems via our framework motivates several interesting combinatorial problems related to product of permutations, some of which are studied in this paper as well.",
        "subjects": "Combinatorics (math.CO)",
        "authors": "Ricky X. F. Chen, Christian M. Reidys,",
        "date": "2015-2-7"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.07838",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.07838",
        "title": "\nRectangular maximum-volume submatrices and their applications",
        "abstract": "A definition of -volume of rectangular matrices is given. We generalize the results for square maximum-volume submatrices to the case rectangular maximal-volume submatrices and provide estimates for the growth of the coefficients. Three promising applications of such submatrices are presented: recommender systems, finding maximal elements in low-rank matrices and preconditioning of overdetermined linear systems. The code is available online at url.",
        "subjects": "Numerical Analysis (math.NA)",
        "authors": "A. Yu. Mikhalev, I. V. Oseledets,",
        "date": "2015-2-27"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.07816",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.07816",
        "title": "\nPuzzle Imaging: Using Large-scale Dimensionality Reduction Algorithms  for Localization",
        "abstract": "Current high-resolution imaging techniques require an intact sample that preserves spatial relationships. We here present a novel approach, \"puzzle imaging,\" that allows imaging a spatially scrambled sample. This technique takes many spatially disordered samples, and then pieces them back together using local properties embedded within the sample. We show that puzzle imaging can efficiently produce high-resolution images using dimensionality reduction algorithms. We demonstrate the theoretical capabilities of puzzle imaging in three biological scenarios, showing that (1) relatively precise 3-dimensional brain imaging is possible; (2) the physical structure of a neural network can often be recovered based only on the neural connectivity matrix; and (3) a chemical map could be reproduced using bacteria with chemosensitive DNA and conjugative transfer. The ability to reconstruct scrambled images promises to enable imaging based on DNA sequencing of homogenized tissue samples.",
        "subjects": "Neurons and Cognition (q-bio.NC)",
        "authors": "Joshua I. Glaser, Bradley M. Zamft, George M. Church, Konrad P. Kording,",
        "date": "2015-2-7"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.07758",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.07758",
        "title": "\nFast and accurate prediction of numerical relativity waveforms from  binary black hole mergers using surrogate models",
        "abstract": "Simulating a binary black hole coalescence by solving Einstein's equations is computationally expensive, requiring days to months of supercomputing time. In this paper, we construct an accurate and fast-to-evaluate surrogate model for numerical relativity (NR) waveforms from non-spinning binary black hole coalescences with mass ratios from to and durations corresponding to about orbits before merger. Our surrogate, which is built using reduced order modeling techniques, is distinct from traditional modeling efforts. We find that the full multi-mode surrogate model agrees with waveforms generated by NR to within the numerical error of the NR code. In particular, we show that our modeling strategy produces surrogates which can correctly predict NR waveforms that were used for the surrogate's training. For all practical purposes, then, the surrogate waveform model is equivalent to the high-accuracy, large-scale simulation waveform but can be evaluated in a millisecond to a second depending on the number of output modes and the sampling rate. Our model includes all spherical-harmonic waveform modes that can be resolved by the NR code up to , including modes that are typically difficult to model with other approaches. We assess the model's uncertainty, which could be useful in parameter estimation studies seeking to incorporate model error. We anticipate NR surrogate models to be useful for rapid NR waveform generation in multiple-query applications like parameter estimation, template bank construction, and testing the fidelity of other waveform models.",
        "subjects": "General Relativity and Quantum Cosmology (gr-qc)",
        "authors": "Jonathan Blackman, Scott E. Field, Chad R. Galley, Bela Szilagyi, Mark A. Scheel, Manuel Tiglio, Daniel A. Hemberger,",
        "date": "2015-2-26"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.07738",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.07738",
        "title": "\nAchieving Exact Cluster Recovery Threshold via Semidefinite Programming:  Extensions",
        "abstract": "Recently it has been shown in cite that the semidefinite programming (SDP) relaxation of the maximum likelihood estimator achieves the sharp threshold for exactly recovering the community strucuture under the binary stochastic block model of two equal-sized clusters. Extending the techniques in cite, in this paper we show that SDP relaxations also achieve the sharp recovery threshold in the following cases: (1) Binary stochastic block model with two clusters of sizes proportional to but not necessarily equal; (2) Stochastic block model with a fixed number of equal-sized clusters; (3) Binary censored block model with the background graph being Erd Hs-R 'enyi.",
        "subjects": "Machine Learning (stat.ML)",
        "authors": "Bruce Hajek, Yihong Wu, Jiaming Xu,",
        "date": "2015-2-26"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.07697",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.07697",
        "title": "\nA Chaining Algorithm for Online Nonparametric Regression",
        "abstract": "We consider the problem of online nonparametric regression with arbitrary deterministic sequences. Using ideas from the chaining technique, we design an algorithm that achieves a Dudley-type regret bound similar to the one obtained in a non-constructive fashion by Rakhlin and Sridharan (2014). Our regret bound is expressed in terms of the metric entropy in the sup norm, which yields optimal guarantees when the metric and sequential entropies are of the same order of magnitude. In particular our algorithm is the first one that achieves optimal rates for online regression over Hlder balls. In addition we show for this example how to adapt our chaining algorithm to get a reasonable computational efficiency with similar regret guarantees (up to a log factor).",
        "subjects": "Machine Learning (stat.ML)",
        "authors": "Pierre Gaillard, S\u00e9bastien Gerchinovitz,",
        "date": "2015-2-26"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.07645",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.07645",
        "title": "\nPrivacy for Free: Posterior Sampling and Stochastic Gradient Monte Carlo",
        "abstract": "We consider the problem of Bayesian learning on sensitive datasets and present two simple but somewhat surprising results that connect Bayesian learning to \"differential privacy:, a cryptographic approach to protect individual-level privacy while permiting database-level utility. Specifically, we show that that under standard assumptions, getting one single sample from a posterior distribution is differentially private \"for free\". We will see that estimator is statistically consistent, near optimal and computationally tractable whenever the Bayesian model of interest is consistent, optimal and tractable. Similarly but separately, we show that a recent line of works that use stochastic gradient for Hybrid Monte Carlo (HMC) sampling also preserve differentially privacy with minor or no modifications of the algorithmic procedure at all, these observations lead to an \"anytime\" algorithm for Bayesian learning under privacy constraint. We demonstrate that it performs much better than the state-of-the-art differential private methods on synthetic and real datasets.",
        "subjects": "Machine Learning (stat.ML)",
        "authors": "Yu-Xiang Wang, Stephen E. Fienberg, Alex Smola,",
        "date": "2015-2-26"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.07641",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.07641",
        "title": "\nROCKET: Robust Confidence Intervals via Kendall's Tau for  Transelliptical Graphical Models",
        "abstract": "Undirected graphical models are used extensively in the biological and social sciences to encode a pattern of conditional independences between variables, where the absence of an edge between two nodes and indicates that the corresponding two variables and are believed to be conditionally independent, after controlling for all other measured variables. In the Gaussian case, conditional independence corresponds to a zero entry in the precision matrix (the inverse of the covariance matrix ). Real data often exhibits heavy tail dependence between variables, which cannot be captured by the commonly-used Gaussian or nonparanormal (Gaussian copula) graphical models. In this paper, we study the transelliptical model, an elliptical copula model that generalizes Gaussian and nonparanormal models to a broader family of distributions. We propose the ROCKET method, which constructs an estimator of that we prove to be asymptotically normal under mild assumptions. Empirically, ROCKET outperforms the nonparanormal and Gaussian models in terms of achieving accurate inference on simulated data. We also compare the three methods on real data (daily stock returns), and find that the ROCKET estimator is the only method whose behavior across subsamples agrees with the distribution predicted by the theory.",
        "subjects": "Statistics Theory (math.ST)",
        "authors": "Rina Foygel Barber, Mladen Kolar,",
        "date": "2015-2-26"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.07555",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.07555",
        "title": "\nSupport for Eschenmoser's Glyoxylate Scenario",
        "abstract": "A core topic of research in prebiotic chemistry is the search for plausible synthetic routes that connect the building blocks of modern life such as sugars, nucleotides, amino acids, and lipids to \"molecular food sources\" that have likely been abundant on Early Earth. In a recent contribution, Albert Eschenmoser emphasised the importance of catalytic and autocatalytic cycles in establishing such abiotic synthesis pathways. The accumulation of intermediate products furthermore provides additional catalysts that allow pathways to change over time. We show here that generative models of chemical spaces based on graph grammars make it possible to study such phenomena is a systematic manner. In addition to repro- ducing the key steps of Eschenmoser's hypothesis paper, we discovered previously unexplored potentially autocatalytic pathways from HCN to glyoxylate. A cascading of autocatalytic cycles could efficiently re-route matter, distributed over the combinatorial complex network of HCN hydrolysation chemistry, towards a potential primordial metabolism. The generative approach also has it intrinsic limitations: the unsupervised expansion of the chemical space remains infeasible due to the exponential growth of possible molecules and reactions between them. Here in particular the combinatorial complexity of the HCN polymerisation and hydrolysation networks forms the computational bottleneck. As a consequence, guidance of the computational exploration by chemical experience is indispensable.",
        "subjects": "Molecular Networks (q-bio.MN)",
        "authors": "Jakob L. Andersen, Christoph Flamm, Daniel Merkle, Peter F. Stadler,",
        "date": "2015-2-26"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.07523",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.07523",
        "title": "\nCramer-Rao Bound for Sparse Signals Fitting the Low-Rank Model with  Small Number of Parameters",
        "abstract": "In this paper, we consider signals with a low-rank covariance matrix which reside in a low-dimensional subspace and can be written in terms of a finite (small) number of parameters. Although such signals do not necessarily have a sparse representation in a finite basis, they possess a sparse structure which makes it possible to recover the signal from compressed measurements. We study the statistical performance bound for parameter estimation in the low-rank signal model from compressed measurements. Specifically, we derive the Cramer-Rao bound (CRB) for a generic low-rank model and we show that the number of compressed samples needs to be larger than the number of sources for the existence of an unbiased estimator with finite estimation variance. We further consider the applications to direction-of-arrival (DOA) and spectral estimation which fit into the low-rank signal model. We also investigate the effect of compression on the CRB by considering numerical examples of the DOA estimation scenario, and show how the CRB increases by increasing the compression or equivalently reducing the number of compressed samples.",
        "subjects": "Statistics Theory (math.ST)",
        "authors": "Mahdi Shaghaghi, Sergiy A. Vorobyov,",
        "date": "2015-2-26"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.07484",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.07484",
        "title": "\nGraphs with no induced wheel or antiwheel",
        "abstract": "A wheel is a graph that consists of a chordless cycle of length at least 4 plus a vertex with at least three neighbors on the cycle. It was shown recently that detecting induced wheels is an NP-complete problem. In contrast, it is shown here that graphs that contain no wheel and no antiwheel have a very simple structure and consequently can be recognized in polynomial time.",
        "subjects": "Combinatorics (math.CO)",
        "authors": "Fr\u00e9d\u00e9ric Maffray,",
        "date": "2015-2-26"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.07410",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.07410",
        "title": "\nTowards Constructing Ramanujan Graphs Using Shift Lifts",
        "abstract": "In a breakthrough work, Marcus-Spielman-Srivastava recently showed that every -regular bipartite Ramanujan graph has a 2-lift that is also -regular bipartite Ramanujan. As a consequence, a straightforward iterative brute-force search algorithm leads to the construction of a -regular bipartite Ramanujan graph on vertices in time . Shift -lifts studied by Agarwal-Kolla-Madan lead to a natural approach for constructing Ramanujan graphs more efficiently. The number of possible shift -lifts of a -regular -vertex graph is . Suppose the following holds for : There exists a shift -lift that maintains the Ramanujan property of -regular bipartite graphs on vertices for all . (*) Then, by performing a similar brute-force search algorithm, one would be able to construct an -vertex bipartite Ramanujan graph in time . Furthermore, if (*) holds for all , then one would obtain an algorithm that runs in time. In this work, we take a first step towards proving (*) by showing the existence of shift -lifts that preserve the Ramanujan property in -regular bipartite graphs for .",
        "subjects": "Combinatorics (math.CO)",
        "authors": "Karthekeyan Chandrasekaran, Ameya Velingker,",
        "date": "2015-2-6"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.07363",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.07363",
        "title": "\nEntropy of finite random binary sequences with weak long-range  correlations",
        "abstract": "We study the N-step binary stationary ergodic Markov chain and analyze its differential entropy. Supposing that the correlations are weak we express the conditional probability function of the chain through the pair correlation function and represent the entropy as a functional of the pair correlator. Since the model uses the two-point correlators instead of the block probability, it makes it possible to calculate the entropy of strings at much longer distances than using standard methods. A fluctuation contribution to the entropy due to finiteness of random chains is examined. This contribution can be of the same order as its regular part even at the relatively short lengths of subsequences. A self-similar structure of entropy with respect to the decimation transformations is revealed for some specific forms of the pair correlation function. Application of the theory to the DNA sequence of the R3 chromosome of Drosophila melanogaster is presented.",
        "subjects": "Statistical Mechanics (cond-mat.stat-mech)",
        "authors": "S.S. Melnik, O.V. Usatenko,",
        "date": "2015-1-19"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.07310",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.07310",
        "title": "\nPantheon: A Dataset for the Study of Global Cultural Production",
        "abstract": "We present the Pantheon 1.0 dataset: a manually curated dataset of individuals that have transcended linguistic, temporal, and geographic boundaries. The Pantheon 1.0 dataset includes the 11,341 biographies present in more than 25 languages in Wikipedia and is enriched with: (i) manually curated demographic information (place of birth, date of birth, and gender), (ii) a cultural domain classification categorizing each biography at three levels of aggregation (i.e. Arts/Fine Arts/Painting), and (iii) measures of global visibility (fame) including the number of languages in which a biography is present in Wikipedia, the monthly page-views received by a biography (2008-2013), and a global visibility metric we name the Historical Popularity Index (HPI). We validate our measures of global visibility (HPI and Wikipedia language editions) using external measures of accomplishment in several cultural domains: Tennis, Swimming, Car Racing, and Chess. In all of these cases we find that measures of accomplishments and fame (HPI) correlate with an , suggesting that measures of global fame are appropriate proxies for measures of accomplishment.",
        "subjects": "Physics and Society (physics.soc-ph)",
        "authors": "Amy Zhao Yu, Shahar Ronen, Kevin Hu, Tiffany Lu, C\u00e9sar A. Hidalgo,",
        "date": "2015-2-25"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.07281",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.07281",
        "title": "\nA problem related to the divisibility of exponential sums",
        "abstract": "Francis Castro, et al computed the exact divisibility of families of exponential sums associated to binomials F(X) = aXd1 + bXd2 over Fp, and a conjecture is presented for related work. Here we study this question.",
        "subjects": "Number Theory (math.NT)",
        "authors": "Xiaogang Liu,",
        "date": "2015-2-23"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.07229",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.07229",
        "title": "\nOnline Pairwise Learning Algorithms with Kernels",
        "abstract": "Pairwise learning usually refers to a learning task which involves a loss function depending on pairs of examples, among which most notable ones include ranking, metric learning and AUC maximization. In this paper, we study an online algorithm for pairwise learning with a least-square loss function in an unconstrained setting of a reproducing kernel Hilbert space (RKHS), which we refer to as the Online Pairwise lEaRning Algorithm (OPERA). In contrast to existing works cite which require that the iterates are restricted to a bounded domain or the loss function is strongly-convex, OPERA is associated with a non-strongly convex objective function and learns the target function in an unconstrained RKHS. Specifically, we establish a general theorem which guarantees the almost surely convergence for the last iterate of OPERA without any assumptions on the underlying distribution. Explicit convergence rates are derived under the condition of polynomially decaying step sizes. We also establish an interesting property for a family of widely-used kernels in the setting of pairwise learning and illustrate the above convergence results using such kernels. Our methodology mainly depends on the characterization of RKHSs using its associated integral operators and probability inequalities for random variables with values in a Hilbert space.",
        "subjects": "Machine Learning (stat.ML)",
        "authors": "Yiming Ying, Ding-Xuan Zhou,",
        "date": "2015-2-25"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.07193",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.07193",
        "title": "\nLocal minimization algorithms for dynamic programming equations",
        "abstract": "The numerical realization of the dynamic programming principle for continuous-time optimal control leads to nonlinear Hamilton-Jacobi-Bellman equations which require the minimization of a nonlinear mapping over the set of admissible controls. This minimization is often performed by comparison over a finite number of elements of the control set. In this paper we demonstrate the importance of an accurate realization of these minimization problems and propose algorithms by which this can be achieved effectively. The considered class of equations includes nonsmooth control problems with -penalization which lead to sparse controls.",
        "subjects": "Optimization and Control (math.OC)",
        "authors": "Dante Kalise, Axel Kr\u00f6ner, Karl Kunisch,",
        "date": "2015-2-25"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.07190",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.07190",
        "title": "\nLatent quality models for document networks",
        "abstract": "We present the latent quality model (LQM) for joint modeling of topics and citations in document networks. The LQM combines the strengths of the latent Dirichlet allocation (LDA) and the mixed membership stochastic blockmodel (MMB), and associates each document with a latent quality score. This score provides a topic-free measure of the impact of a document, which is different from the raw count of citations. We develop an efficient algorithm for fitting the LQM using variational methods. To scale up to large networks, we develop an online variant using stochastic gradient methods and case-control likelihood approximation. We evaluate the performance of the LQM using the benchmark KDD Cup 2003 dataset with approximately 30,000 high energy physics papers and demonstrate that LQM can improve citation prediction significantly.",
        "subjects": "Machine Learning (stat.ML)",
        "authors": "Linda S. L. Tan, Aik Hui Chan, Tian Zheng,",
        "date": "2015-2-25"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.07045",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.07045",
        "title": "\nWhich phylogenetic networks are merely trees with additional arcs?",
        "abstract": "A binary phylogenetic network may or may not be obtainable from a tree by the addition of directed edges (arcs) between tree arcs. Here, we establish a precise and easily tested criterion (based on `antichains') that efficiently determines whether or not any given network can be realized in this way. Moreover, the proof provides a polynomial-time algorithm for finding one or more trees (when they exist) on which the network can be based. A number of interesting consequences are presented as corollaries; these lead to some further relevant questions and observations, which we outline in the conclusion.",
        "subjects": "Populations and Evolution (q-bio.PE)",
        "authors": "Andrew R. Francis, Mike Steel,",
        "date": "2015-2-25"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.07016",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.07016",
        "title": "\nTriadic analysis of affiliation networks",
        "abstract": "The widely-used notion of triadic closure has been conceptualized and measured in a variety of ways, most famously the clustering coefficient. This paper proposes a measure of triadic closure in affiliation networks designed to control for the influence of bicliques. In order to avoid arbitrariness, the paper introduces a triadic framework for affiliation networks, within which a range of possible statistics can be considered; it then takes an axiomatic approach to narrowing this range. The paper conducts an instrumental assessment of the proposed statistic alongside two previous proposals, for reliability, validity, and usefulness. Finally, these tools demonstrate their collective applicability in a multi-perspective investigation into triadic closure in several empirical social networks.",
        "subjects": "Combinatorics (math.CO)",
        "authors": "Jason Cory Brunson,",
        "date": "2015-2-25"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06967",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06967",
        "title": "\nComputing the Degenerate Ground Space of Gapped Spin Chains in  Polynomial Time",
        "abstract": "Given a gapped Hamiltonian of a spin chain, we give a polynomial-time algorithm for finding the degenerate ground space projector. The output is an orthonormal set of matrix product states that approximate the true ground space projector up to an inverse polynomial error in any Schatten norm, with a runtime exponential in the degeneracy. Our algorithm is an extension of the recent algorithm of Landau, Vazirani, and Vidick for the nondegenerate case, and it includes the recent improvements due to Huang. The main new idea is to incorporate the local distinguishability of ground states on the half-chain to ensure that the algorithm returns a complete set of global ground states.",
        "subjects": "Quantum Physics (quant-ph)",
        "authors": "Christopher T. Chubb, Steven T. Flammia,",
        "date": "2015-2-24"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06910",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06910",
        "title": "\nThe Spontaneous Emergence of Conventions: An Experimental Study of  Cultural Evolution",
        "abstract": "How do shared conventions emerge in complex decentralized social systems? This question engages fields as diverse as linguistics, sociology and cognitive science. Previous empirical attempts to solve this puzzle all presuppose that formal or informal institutions, such as incentives for global agreement, coordinated leadership, or aggregated information about the population, are needed to facilitate a solution. Evolutionary theories of social conventions, by contrast, hypothesize that such institutions are not necessary in order for social conventions to form. However, empirical tests of this hypothesis have been hindered by the difficulties of evaluating the real-time creation of new collective behaviors in large decentralized populations. Here, we present experimental results - replicated at several scales - that demonstrate the spontaneous creation of universally adopted social conventions, and show how simple changes in a population's network structure can direct the dynamics of norm formation, driving human populations with no ambition for large scale coordination to rapidly evolve shared social conventions.",
        "subjects": "Physics and Society (physics.soc-ph)",
        "authors": "Damon Centola, Andrea Baronchelli,",
        "date": "2015-2-24"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06895",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06895",
        "title": "\nOn the consistency theory of high dimensional variable screening",
        "abstract": "Variable screening is a fast dimension reduction technique for assisting high dimensional feature selection. As a preselection method, it selects a moderate size subset of candidate variables for further refining via feature selection to produce the final model. The performance of variable screening depends on both computational efficiency and the ability to dramatically reduce the number of variables without discarding the important ones. When the data dimension is substantially larger than the sample size , variable screening becomes crucial as 1) Faster feature selection algorithms are needed; 2) Conditions guaranteeing selection consistency might fail to hold. par This article studies a class of linear screening methods and establishes consistency theory for this special class. In particular, we prove the weak diagonally dominant (WDD) condition is a necessary and sufficient condition for strong screening consistency. As concrete examples, we show two screening methods and are both strong screening consistent (subject to additional constraints) with large probability if under random designs. In addition, we relate the WDD condition to the irrepresentable condition, and highlight limitations of .",
        "subjects": "Statistics Theory (math.ST)",
        "authors": "Xiangyu Wang, Chenlei Leng, David B. Dunson,",
        "date": "2015-2-24"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06866",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06866",
        "title": "\nDaily rhythms in mobile telephone communication",
        "abstract": "Circadian rhythms are known to be important drivers of human activity and the recent availability of electronic records of human behaviour has provided fine-grained data of temporal patterns of activity on a large scale. Further, questionnaire studies have identified important individual differences in circadian rhythms, with people broadly categorised into morning-like or evening-like individuals. However, little is known about the social aspects of these circadian rhythms, or how they vary across individuals. In this study we use a unique 18-month dataset that combines mobile phone calls and questionnaire data to examine individual differences in the daily rhythms of mobile phone activity. We demonstrate clear individual differences in daily patterns of phone calls, and show that these individual differences are persistent despite a high degree of turnover in the individuals' social networks. Further, women's calls were longer than men's calls, especially during the evening and at night, and these calls were typically focused on a small number of emotionally intense relationships. These results demonstrate that individual differences in circadian rhythms are not just related to broad patterns of morningness and eveningness, but have a strong social component, in directing phone calls to specific individuals at specific times of day.",
        "subjects": "Physics and Society (physics.soc-ph)",
        "authors": "Talayeh Aledavood, Eduardo L\u00f3pez, Sam G. B. Roberts, Felix Reed-Tsochas, Esteban Moro, Robin I. M. Dunbar, Jari Saram\u00e4ki,",
        "date": "2015-2-24"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06797",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06797",
        "title": "\nApproximation of high-dimensional parametric PDEs",
        "abstract": "Parametrized families of PDEs arise in various contexts such as inverse problems, control and optimization, risk assessment, and uncertainty quantification. In most of these applications, the number of parameters is large or perhaps even infinite. Thus, the development of numerical methods for these parametric problems is faced with the possible curse of dimensionality. This article is directed at (i) identifying and understanding which properties of parametric equations allow one to avoid this curse and (ii) developing and analyzing effective numerical methodd which fully exploit these properties and, in turn, are immune to the growth in dimensionality. The first part of this article studies the smoothness and approximability of the solution map, that is, the map where is the parameter value and is the corresponding solution to the PDE. It is shown that for many relevant parametric PDEs, the parametric smoothness of this map is typically holomorphic and also highly anisotropic in that the relevant parameters are of widely varying importance in describing the solution. These two properties are then exploited to establish convergence rates of -term approximations to the solution map for which each term is separable in the parametric and physical variables. These results reveal that, at least on a theoretical level, the solution map can be well approximated by discretizations of moderate complexity, thereby showing how the curse of dimensionality is broken. This theoretical analysis is carried out through concepts of approximation theory such as best -term approximation, sparsity, and -widths. These notions determine a priori the best possible performance of numerical methods and thus serve as a benchmark for concrete algorithms. The second part of this article turns to the development of numerical algorithms based on the theoretically established sparse separable approximations. The numerical methods studied fall into two general categories. The first uses polynomial expansions in terms of the parameters to approximate the solution map. The second one searches for suitable low dimensional spaces for simultaneously approximating all members of the parametric family. The numerical implementation of these approaches is carried out through adaptive and greedy algorithms. An a priori analysis of the performance of these algorithms establishes how well they meet the theoretical benchmarks.",
        "subjects": "Analysis of PDEs (math.AP)",
        "authors": "Albert Cohen, Ronald Devore,",
        "date": "2015-2-4"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06795",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06795",
        "title": "\nKolmogorov widths under holomorphic mappings",
        "abstract": "If is a bounded linear operator mapping the Banach space into the Banach space and is a compact set in , then the Kolmogorov widths of the image do not exceed those of multiplied by the norm of . We extend this result from linear maps to holomorphic mappings from to in the following sense: when the widths of are for some , then those of are for any , We then use these results to prove various theorems about Kolmogorov widths of manifolds consisting of solutions to certain parametrized PDEs. Results of this type are important in the numerical analysis of reduced bases and other reduced modeling methods, since the best possible performance of such methods is governed by the rate of decay of the Kolmogorov widths of the solution manifold.",
        "subjects": "Analysis of PDEs (math.AP)",
        "authors": "Albert Cohen, Ronald Devore,",
        "date": "2015-2-24"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06777",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06777",
        "title": "\nStatistical efficiency of structured cpd estimation applied to  Wiener-Hammerstein modeling",
        "abstract": "The computation of a structured canonical polyadic de-composition (CPD) is useful to address several important modeling problems in real-world applications. In this paper, we consider the identification of a nonlinear system by means of a Wiener-Hammerstein model, assuming a high-order Volterra kernel of that system has been previously estimated. Such a kernel, viewed as a tensor, admits a CPD with banded circulant factors which comprise the model parameters. To estimate them, we formulate specialized estimators based on recently proposed algorithms for the computation of struc-tured CPDs. Then, considering the presence of additive white Gaussian noise, we derive a closed-form expression for the Cramer-Rao bound (CRB) associated with this estimation problem. Finally, we assess the statistical performance of the proposed estimators via Monte Carlo simulations, by comparing their mean-square error with the CRB.",
        "subjects": "Computation (stat.CO)",
        "authors": "Jos\u00e9 Henrique De Morais Goulart, Maxime Boizard, R\u00e9my Boyer, G\u00e9rard Favier, Pierre Comon,",
        "date": "2015-2-24"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06759",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06759",
        "title": "\nA Logic of Quantum Measurement",
        "abstract": "We present a formulation of quantum mechanics based on a logic representing some aspects of the behaviour of the measurement process. With such an approach, we make no direct mention of quantum states, and thus avoid the problems associated to this rather evasive notion. We then study some properties of the models of this logic, and deduce some characteristics that any model (and hence any formulation of quantum mechanics compatible with its prediction and relying on a notion of measurement) should verify. The main results we obtain are that in the case of a Hilbert space of dimension at least 3, no model can lead to the prediction with certainty of more than one atomic outcome. Moreover, if the Hilbert space is finite dimensional, then we are able to precisely describe the structure of the predictions of any model of our logic. As a consequence, we finally show that all the models of our logic make exactly the same predictions regarding whether a given sequence of outcomes is possible or not.",
        "subjects": "Quantum Physics (quant-ph)",
        "authors": "Olivier Brunet,",
        "date": "2015-2-24"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06644",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06644",
        "title": "\nOn The Identifiability of Mixture Models from Grouped Samples",
        "abstract": "Finite mixture models are statistical models which appear in many problems in statistics and machine learning. In such models it is assumed that data are drawn from random probability measures, called mixture components, which are themselves drawn from a probability measure P over probability measures. When estimating mixture models, it is common to make assumptions on the mixture components, such as parametric assumptions. In this paper, we make no assumption on the mixture components, and instead assume that observations from the mixture model are grouped, such that observations in the same group are known to be drawn from the same component. We show that any mixture of m probability measures can be uniquely identified provided there are 2m-1 observations per group. Moreover we show that, for any m, there exists a mixture of m probability measures that cannot be uniquely identified when groups have 2m-2 observations. Our results hold for any sample space with more than one element.",
        "subjects": "Machine Learning (stat.ML)",
        "authors": "Robert A. Vandermeulen, Clayton D. Scott,",
        "date": "2015-2-23"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06631",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06631",
        "title": "\nPolynomial Interpolation and Identity Testing from High Powers over  Finite Fields",
        "abstract": "We consider the problem of recovering (that is, interpolating) and identity testing of a \"hidden\" monic polynomial , given an oracle access to for (extension fields access is not permitted). The naive interpolation algorithm needs queries and thus requires . We design algorithms that are asymptotically better in certain cases; requiring only queries to the oracle. In the randomized (and quantum) setting, we give a substantially better interpolation algorithm, that requires only queries. Such results have been known before only for the special case of a linear , called the hidden shifted power problem. We use techniques from algebra, such as effective versions of Hilbert's Nullstellensatz, and analytic number theory, such as results on the distribution of rational functions in subgroups and character sum estimates.",
        "subjects": "Number Theory (math.NT)",
        "authors": "Gabor Ivanyos, Marek Karpinski, Miklos Santha, Nitin Saxena, Igor Shparlinski,",
        "date": "2015-2-23"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06501",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06501",
        "title": "\nKnowledge Discovery Framework for the Virtual Observatory",
        "abstract": "We describe a framework that allows a scientist-user to easily query for information across all Virtual Observatory (VO) repositories and pull it back for analysis. This framework hides the gory details of meta-data remediation and data formatting from the user, allowing them to get on with search, retrieval and analysis of VO data as if they were drawn from a single source using a science based terminology rather than a data-centric one.",
        "subjects": "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "authors": "Brian Thomas, Edward Shaya, Zenping Huang, Peter Teuben,",
        "date": "2015-2-23"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06492",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06492",
        "title": "\nA User Interface for Semantically Oriented Data Mining of Astronomy  Repositories",
        "abstract": "We present a user-friendly, but powerful interface for the data mining of scientific repositories. We present the tool in use with actual astronomy data and show how it may be used to achieve many different types of powerful semantic queries. The tool itself hides the gory details of query formulation, and data retrieval from the user, and allows the user to create workflows which may be used to transform the data into a convenient form.",
        "subjects": "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "authors": "Brian Thomas, Edward Shaya,",
        "date": "2015-2-23"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06471",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06471",
        "title": "\nRestricted density classification in one dimension",
        "abstract": "The density classification task is to determine which of the symbols appearing in an array has the majority. A cellular automaton solving this task is required to converge to a uniform configuration with the majority symbol at each site. It is not known whether a one-dimensional cellular automaton with binary alphabet can classify all Bernoulli random configurations almost surely according to their densities. We show that any cellular automaton that washes out finite islands in linear time classifies all Bernoulli random configurations with parameters close to 0 or 1 almost surely correctly. The proof is a direct application of a \"percolation\" argument, which goes back to G 'acs (1986).",
        "subjects": "Probability (math.PR)",
        "authors": "Siamak Taati,",
        "date": "2015-2-23"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.00178",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.00178",
        "title": "\nLattices with Symmetry",
        "abstract": "For large ranks, there is no good algorithm that decides whether a given lattice has an orthonormal basis. But when the lattice is given with enough symmetry, we can construct a provably deterministic polynomial-time algorithm to accomplish this, based on the work of Gentry and Szydlo. The techniques involve algorithmic algebraic number theory, analytic number theory, commutative algebra, and lattice basis reduction.",
        "subjects": "Number Theory (math.NT)",
        "authors": "H. W. Lenstra Jr., A. Silverberg,",
        "date": "2014-12-31"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06434",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06434",
        "title": "\nANN Model to Predict Stock Prices at Stock Exchange Markets",
        "abstract": "Stock exchanges are considered major players in financial sectors of many countries. Most Stockbrokers, who execute stock trade, use technical, fundamental or time series analysis in trying to predict stock prices, so as to advise clients. However, these strategies do not usually guarantee good returns because they guide on trends and not the most likely price. It is therefore necessary to explore improved methods of prediction. The research proposes the use of Artificial Neural Network that is feedforward multi-layer perceptron with error backpropagation and develops a model of configuration 5:21:21:1 with 80% training data in 130,000 cycles. The research develops a prototype and tests it on 2008-2012 data from stock markets e.g. Nairobi Securities Exchange and New York Stock Exchange, where prediction results show MAPE of between 0.71% and 2.77%. Validation done with Encog and Neuroph realized comparable results. The model is thus capable of prediction on typical stock markets.",
        "subjects": "Statistical Finance (q-fin.ST)",
        "authors": "B. W. Wanjawa, L. Muchemi,",
        "date": "2014-12-17"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.00375",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.00375",
        "title": "\nPassing Expectation Propagation Messages with Kernel Methods",
        "abstract": "We propose to learn a kernel-based message operator which takes as input all expectation propagation (EP) incoming messages to a factor node and produces an outgoing message. In ordinary EP, computing an outgoing message involves estimating a multivariate integral which may not have an analytic expression. Learning such an operator allows one to bypass the expensive computation of the integral during inference by directly mapping all incoming messages into an outgoing message. The operator can be learned from training data (examples of input and output messages) which allows automated inference to be made on any kind of factor that can be sampled.",
        "subjects": "Machine Learning (stat.ML)",
        "authors": "Wittawat Jitkrittum, Arthur Gretton, Nicolas Heess,",
        "date": "2015-1-2"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06430",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06430",
        "title": "\nA Bottom-up Approach to Opinion Dynamics: a Cognitive Model",
        "abstract": "The study of opinions - e.g., their formation and change, and their effects on our society - by means of theoretical and numerical models has been one of the main goals of sociophysics until now, but it is one of the defining topics addressed by social psychology and complexity science. Despite the flourishing of different models and theories, several key questions still remain unanswered. Aim of this paper is to provide a cognitively grounded computational model of opinions in which they are described as mental representations and defined in terms of distinctive mental features. We also define how these representations change dynamically through different processes, describing the interplay between mental and social dynamics of opinions. We present two versions of the model, one with discrete opinions (voter model-like), and one with continuous ones (Deffuant-like). By means of numerical simulations, we compare the behaviour of our cognitive model with the classical sociophysical models, showing how consensus is reached in either.",
        "subjects": "Physics and Society (physics.soc-ph)",
        "authors": "Francesca Giardini, Daniele Vilone, Rosaria Conte,",
        "date": "2015-2-23"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.07430",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.07430",
        "title": "\nBayesian Hierarchical Clustering with Exponential Family: Small-Variance  Asymptotics and Reducibility",
        "abstract": "Bayesian hierarchical clustering (BHC) is an agglomerative clustering method, where a probabilistic model is defined and its marginal likelihoods are evaluated to decide which clusters to merge. While BHC provides a few advantages over traditional distance-based agglomerative clustering algorithms, successive evaluation of marginal likelihoods and careful hyperparameter tuning are cumbersome and limit the scalability. In this paper we relax BHC into a non-probabilistic formulation, exploring small-variance asymptotics in conjugate-exponential models. We develop a novel clustering algorithm, referred to as relaxed BHC (RBHC), from the asymptotic limit of the BHC model that exhibits the scalability of distance-based agglomerative clustering algorithms as well as the flexibility of Bayesian nonparametric models. We also investigate the reducibility of the dissimilarity measure emerged from the asymptotic limit of the BHC model, allowing us to use scalable algorithms such as the nearest neighbor chain algorithm. Numerical experiments on both synthetic and real-world datasets demonstrate the validity and high performance of our method.",
        "subjects": "Machine Learning (stat.ML)",
        "authors": "Juho Lee, Seungjin Choi,",
        "date": "2015-1-29"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06381",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06381",
        "title": "\nThe ALICE analysis train system",
        "abstract": "In the ALICE experiment hundreds of users are analyzing big datasets on a Grid system. High throughput and short turn-around times are achieved by a centralized system called the LEGO trains. This system combines analysis from different users in so-called analysis trains which are then executed within the same Grid jobs thereby reducing the number of times the data needs to be read from the storage systems. The centralized trains improve the performance, the usability for users and the bookkeeping in comparison to single user analysis. The train system builds upon the already existing ALICE tools, i.e. the analysis framework as well as the Grid submission and monitoring infrastructure. The entry point to the train system is a web interface which is used to configure the analysis and the desired datasets as well as to test and submit the train. Several measures have been implemented to reduce the time a train needs to finish and to increase the CPU efficiency.",
        "subjects": "High Energy Physics - Experiment (hep-ex)",
        "authors": "Markus Zimmermann, ALICE collaboration,",
        "date": "2015-2-23"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.07788",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.07788",
        "title": "\nHuman diffusion and city influence",
        "abstract": "Cities are characterized by concentrating population, economic activity and services. However, not all cities are equal and hierarchy in terms of influence at local, regional or global scales naturally emerges. Traditionally, there have been important efforts to describe this hierarchy by indirect measures such the sharing of company headquarters, traffic by air, train or boats or economical exchanges. In this work, we take a different approach and introduce a method that uses geolocated Twitter information to quantify the impact of cities on rural or other urban areas. Since geolocated tweets are becoming a global phenomenon, the method can be applied at a world-wide scale. We focus on cities and analyze the mobility patterns of people after visiting them for the first time. Cities such as Rome and Paris appear consistently as those with largest area covered by Twitter users after their visit and as those attracting visitors most diverse in origin. The study is also performed discerning users mobility by the contribution of locals and non-locals, which shows the relevance of the mixing ratio between them to have a global city. Finally, we focus on the mobility of users between cities and construct a network with the users flows between them. The network allows to analyze centrality defining it at a global and regional scale. The hierarchy of cities dramatically changes when referred only to urban users, with New York and London playing a predominant role.",
        "subjects": "Physics and Society (physics.soc-ph)",
        "authors": "Maxime Lenormand, Bruno Gon\u00e7alves, Ant\u00f2nia Tugores, Jos\u00e9 J. Ramasco,",
        "date": "2015-1-30"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06343",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06343",
        "title": "\nEquistarable bipartite graphs",
        "abstract": "Recently, Milani v and Trotignon introduced the class of equistarable graphs as graphs without isolated vertices admitting positive weights on the edges such that a subset of edges is of total weight if and only if it forms a maximal star. Based on equistarable graphs, counterexamples to three conjectures on equistable graphs were constructed, in particular to Orlin's conjecture, which states that every equistable graph is a general partition graph. In this paper we characterize equistarable bipartite graphs. We show that a bipartite graph is equistarable if and only if every -matching of the graph extends to a matching covering all vertices of degree at least . As a consequence of this result, we obtain that Orlin's conjecture holds within the class of complements of line graphs of bipartite graphs. We also connect equistarable graphs to the triangle condition, a combinatorial condition known to be necessary (but in general not sufficient) for equistability. We show that the triangle condition implies general partitionability for complements of line graphs of forests, and construct an infinite family of triangle non-equistable graphs within the class of complements of line graphs of bipartite graphs.",
        "subjects": "Combinatorics (math.CO)",
        "authors": "Endre Boros, Nina Chiarelli, Martin Milani\u010d,",
        "date": "2015-2-23"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.07773",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.07773",
        "title": "\nPolyhedral Omega: A New Algorithm for Solving Linear Diophantine Systems",
        "abstract": "Polyhedral Omega is a new algorithm for solving linear Diophantine systems (LDS), i.e., for computing a multivariate rational function representation of the set of all non-negative integer solutions to a system of linear equations and inequalities. Polyhedral Omega combines methods from partition analysis with methods from polyhedral geometry. In particular, we combine MacMahon's iterative approach based on the Omega operator and explicit formulas for its evaluation with geometric tools such as Brion decompositions and Barvinok's short rational function representations. In this way, we connect two recent branches of research that have so far remained separate, unified by the concept of symbolic cones which we introduce. The resulting LDS solver Polyhedral Omega is significantly faster than previous solvers based on partition analysis and it is competitive with state-of-the-art LDS solvers based on geometric methods. Most importantly, this synthesis of ideas makes Polyhedral Omega the simplest algorithm for solving linear Diophantine systems available to date. Moreover, we provide an illustrated geometric interpretation of partition analysis, with the aim of making ideas from both areas accessible to readers from a wide range of backgrounds.",
        "subjects": "Combinatorics (math.CO)",
        "authors": "Felix Breuer, Zafeirakis Zafeirakopoulos,",
        "date": "2015-1-30"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06309",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06309",
        "title": "\nLearning with Differential Privacy: Stability, Learnability and the  Sufficiency and Necessity of ERM Principle",
        "abstract": "While machine learning has proven to be a powerful data-driven solution to many real-life problems, its use in sensitive domains that involve human subjects has been limited due to privacy concerns. The cryptographic approach known as \"differential privacy\" offers provable privacy guarantees. In this paper we study the learnability under Vapnik's general learning setting with differential privacy constraint, and reveal some intricate relationships between privacy, stability and learnability. In particular, we show that a problem is privately learnable emph there is a private algorithm that asymptotically minimizes the empirical risk (AERM). This is rather surprising because for non-private learning, AERM alone is not sufficient for learnability. This result suggests that when searching for private learning algorithms, we can restrict the search to algorithms that are AERM. In light of this, we propose a conceptual procedure that always finds a universally consistent algorithm whenever the problem is learnable under privacy constraint. We also propose a generic and practical algorithm and show that under very general conditions it privately learns a wide class of learning problems.",
        "subjects": "Machine Learning (stat.ML)",
        "authors": "Yu-Xiang Wang, Jing Lei, Stephen E. Fienberg,",
        "date": "2015-2-23"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.07758",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.07758",
        "title": "\nGibbs-Ringing Artifact Removal Based on Local Subvoxel-shifts",
        "abstract": "Gibbs-ringing is a well known artifact which manifests itself as spurious oscillations in the vicinity of sharp image transients, e.g. at tissue boundaries. The origin can be seen in the truncation of k-space during MRI data-acquisition. Consequently, correction techniques like Gegenbauer reconstruction or extrapolation methods aim at recovering these missing data. Here, we present a simple and robust method which exploits a different view on the Gibbs-phenomena. The truncation in k-space can be interpreted as a convolution with a sinc-function in image space. Hence, the severity of the artifacts depends on how the sinc-function is sampled. We propose to re-interpolate the image based on local, subvoxel shifts to sample the ringing pattern at the zero-crossings of the oscillating sinc-function. With this, the artifact can effectively and robustly be removed with a minimal amount of smoothing.",
        "subjects": "Medical Physics (physics.med-ph)",
        "authors": "Elias Kellner, Bibek Dhital, Marco Reisert,",
        "date": "2015-1-30"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06287",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06287",
        "title": "\nAsymptotically Exact Error Analysis for the Generalized $\\ell_2^2$-LASSO",
        "abstract": "Given an unknown signal and linear noisy measurements , the generalized -LASSO solves . Here, is a convex regularization function (e.g. -norm, nuclear-norm) aiming to promote the structure of (e.g. sparse, low-rank), and, is the regularizer parameter. A related optimization problem, though not as popular or well-known, is often referred to as the generalized -LASSO and takes the form , and has been analyzed in [1]. [1] further made conjectures about the performance of the generalized -LASSO. This paper establishes these conjectures rigorously. We measure performance with the normalized squared error . Assuming the entries of and be i.i.d. standard normal, we precisely characterize the \"asymptotic NSE\" when the problem dimensions tend to infinity in a proportional manner. The role of and is explicitly captured in the derived expression via means of a single geometric quantity, the Gaussian distance to the subdifferential. We conjecture that . We include detailed discussions on the interpretation of our result, make connections to relevant literature and perform computational experiments that validate our theoretical findings.",
        "subjects": "Statistics Theory (math.ST)",
        "authors": "Christos Thrampoulidis, Ashkan Panahi, Babak Hassibi,",
        "date": "2015-2-22"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.07756",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.07756",
        "title": "\nA Resilient Quantum Secret Sharing Scheme",
        "abstract": "A resilient secret sharing scheme is supposed to generate the secret correctly even after some shares are damaged. In this paper, we show how quantum error correcting codes can be exploited to design a resilient quantum secret sharing scheme, where a quantum state is shared among more than one parties.",
        "subjects": "Quantum Physics (quant-ph)",
        "authors": "Arpita Maitra, Goutam Paul,",
        "date": "2015-1-30"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06277",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06277",
        "title": "\nA cut-invariant law of large numbers for random heaps",
        "abstract": "Heap monoids equipped with Bernoulli measures are a model of probabilistic asynchronous systems. We introduce in this framework the notion of asynchronous stopping time, which is analogous to the notion of stopping time for classical probabilistic processes. A Strong Bernoulli property is proved. A notion of cut-invariance is formulated for convergent ergodic means. Then a version of the Strong law of large numbers is proved for heap monoids with Bernoulli measures. Finally, we study a sub-additive version of the Law of large numbers in this framework based on Kingman sub-additive Ergodic Theorem.",
        "subjects": "Combinatorics (math.CO)",
        "authors": "Samy Abbes,",
        "date": "2015-2-2"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.07721",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.07721",
        "title": "\nAsymmetric polygons with maximum area",
        "abstract": "We say that a polygon inscribed in the circle is asymmetric if it contains no two antipodal points being the endpoints of a diameter. Given diameters of a circle and a positive integer , this paper addresses the problem of computing a maximum area asymmetric -gon having as vertices endpoints of the given diameters. The study of this type of polygons is motivated by ethnomusiciological applications.",
        "subjects": "Metric Geometry (math.MG)",
        "authors": "L. Barba, L.E. Caraballo, J. M. D\u00edaz-B\u00e1\u00f1ez, R. Fabila-Monroy, E. P\u00e9rez-Castillo,",
        "date": "2015-1-30"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06256",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06256",
        "title": "\nSpaced seeds improve metagenomic classification",
        "abstract": "Metagenomics is a powerful approach to study genetic content of environmental samples that has been strongly promoted by NGS technologies. To cope with massive data involved in modern metagenomic projects, recent tools [4, 39] rely on the analysis of k-mers shared between the read to be classified and sampled reference genomes. Within this general framework, we show in this work that spaced seeds provide a significant improvement of classification capacity as opposed to traditional contiguous k-mers. We support this thesis through a series a different computational experiments, including simulations of large-scale metagenomic projects.",
        "subjects": "Genomics (q-bio.GN)",
        "authors": "Karel Brinda, Maciej Sykulski, Gregory Kucherov,",
        "date": "2015-2-2"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.07591",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.07591",
        "title": "\nDirect algebraic solutions to constrained tropical optimization problems",
        "abstract": "We examine a new optimization problem formulated in the tropical mathematics setting as an extension of certain known problems. The problem is to minimize a nonlinear objective function, which is defined on vectors over an idempotent semifield by using multiplicative conjugate transposition, subject to inequality constraints. As compared to the known problems, the new one has a more general objective function and additional constraints. We provide a complete solution in an explicit form to the problem by using an approach that introduces an additional variable to represent the values of the objective function, and then reduces the initial problem to a parametrized vector inequality. The minimum of the objective function is evaluated by applying the existence conditions for the solution of this inequality. A complete solution to the problem is given by the solutions of the inequality, provided the parameter is set to the minimum value. As a consequence, we obtain solutions to new special cases of the general problem. To illustrate the application of the results, we solve a real-world problem drawn from project scheduling, and offer a representative numerical example.",
        "subjects": "Optimization and Control (math.OC)",
        "authors": "N. Krivulin,",
        "date": "2015-1-29"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06236",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06236",
        "title": "\nSome enumerations of binary digital images",
        "abstract": "The topology of digital images has been studied much in recent years, but no attempt has been made to exhaustively catalog the structure of binary images of small numbers of points. We produce enumerations of several classes of digital images up to isomorphism and decide which among them are homotopy equivalent to one another. Noting some patterns in the results, we make some conjectures about digital images which are irreducible but not rigid.",
        "subjects": "Combinatorics (math.CO)",
        "authors": "P. Christopher Staecker,",
        "date": "2015-2-22"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.07529",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.07529",
        "title": "\nQuantum Information splitting using a pair of {\\it GHZ} states",
        "abstract": "We describe a protocol for quantum information splitting (QIS) of a restricted class of three-qubit states among three parties Alice, Bob and Charlie, using a pair of GHZ states as the quantum channel. There are two different forms of this three-qubit state that is used for QIS depending on the distribution of the particles among the three parties. There is also a special type of four-qubit state that can be used for QIS using the above channel. We explicitly construct the quantum channel, Alice's measurement basis and the analytic form of the unitary operations required by the receiver for such a purpose.",
        "subjects": "Quantum Physics (quant-ph)",
        "authors": "Kaushik Nandi, Goutam Paul,",
        "date": "2015-1-29"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06231",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06231",
        "title": "\nLarge epidemic thresholds emerge in heterogeneous networks of  heterogeneous nodes",
        "abstract": "One of the famous results of network science states that networks with heterogeneous connectivity are more susceptible to epidemic spreading than their more homogeneous counterparts. In particular, in networks of identical nodes it has been shown that heterogeneity can lower the epidemic threshold at which epidemics can invade the system. Network heterogeneity can thus allow diseases with lower transmission probabilities to persist and spread. Here, we point out that for real world applications, this result should not be regarded independently of the intra-individual heterogeneity between people. Our results show that, if heterogeneity among people is taken into account, networks that are more heterogeneous in connectivity can be more resistant to epidemic spreading. We study a susceptible-infected-susceptible model with adaptive disease avoidance. Results from this model suggest that this reversal of the effect of network heterogeneity is likely to occur in populations in which the individuals are aware of their subjective disease risk. For epidemiology, this implies that network heterogeneity should not be studied in isolation.",
        "subjects": "Physics and Society (physics.soc-ph)",
        "authors": "Hui Yang, Ming Tang, Thilo Gross,",
        "date": "2015-2-22"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.07469",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.07469",
        "title": "\nOn-line list colouring of random graphs",
        "abstract": "In this paper, the on-line list colouring of binomial random graphs G(n,p) is studied. We show that the on-line choice number of G(n,p) is asymptotically almost surely asymptotic to the chromatic number of G(n,p), provided that the average degree d=p(n-1) tends to infinity faster than (log log n)^1/3(log n)^2n^(2/3). For sparser graphs, we are slightly less successful; we show that if d&gt;(log n)^(2+epsilon) for some epsilon&gt;0, then the on-line choice number is larger than the chromatic number by at most a multiplicative factor of C, where C in [2,4], depending on the range of d. Also, for d=O(1), the on-line choice number is by at most a multiplicative constant factor larger than the chromatic number.",
        "subjects": "Combinatorics (math.CO)",
        "authors": "Alan Frieze, Dieter Mitsche, Xavier P\u00e9rez-Gim\u00e9nez, Pawe\u0142 Pra\u0142at,",
        "date": "2015-1-29"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06222",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06222",
        "title": "\nTropical optimization problems in project scheduling",
        "abstract": "We consider a project that consists of activities operating in parallel under various temporal constraints, including start-start, start-finish and finish-start precedence relations, early start, late start and late finish time boundaries, and due dates. Scheduling problems are formulated to find optimal schedules for the project under different optimality criteria to minimize, including the project makespan, the maximum deviation from the due dates, the maximum flow-time, and the maximum deviation of finish times. We represent the problems as optimization problems in terms of tropical mathematics, and then solve these problems by applying direct solution methods of tropical optimization. As a result, new direct solutions of the problems are obtained in a compact vector form, which is ready for further analysis and practical implementation.",
        "subjects": "Optimization and Control (math.OC)",
        "authors": "Nikolai Krivulin,",
        "date": "2015-2-22"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.07460",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.07460",
        "title": "\nSimple greedy 2-approximation algorithm for the maximum genus of a graph",
        "abstract": "The maximum genus of a graph G is the largest genus of an orientable surface into which G has a cellular embedding. Combinatorially, it coincides with the maximum number of disjoint pairs of adjacent edges of G whose removal results in a connected spanning subgraph of G. In this paper we prove that removing pairs of adjacent edges from G arbitrarily while retaining connectedness leads to at least pairs of edges removed. This allows us to describe a greedy algorithm for the maximum genus of a graph; our algorithm returns an integer k such that , providing a simple method to efficiently approximate maximum genus. As a consequence of our approach we obtain a 2-approximate counterpart of Xuong's combinatorial characterisation of maximum genus.",
        "subjects": "Combinatorics (math.CO)",
        "authors": "Michal Kotrbcik, Martin Skoviera,",
        "date": "2015-1-29"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06197",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06197",
        "title": "\nOn Online Control of False Discovery Rate",
        "abstract": "Multiple hypotheses testing is a core problem in statistical inference and arises in almost every scientific field. Given a sequence of null hypotheses , Benjamini and Hochberg cite introduced the false discovery rate (FDR) criterion, which is the expected proportion of false positives among rejected null hypotheses, and proposed a testing procedure that controls FDR below a pre-assigned significance level. They also proposed a different criterion, called mFDR, which does not control a property of the realized set of tests; rather it controls the ratio of expected number of false discoveries to the expected number of discoveries. In this paper, we propose two procedures for multiple hypotheses testing that we will call \"LOND\" and \"LORD\". These procedures control FDR and mFDR in an emph. Concretely, we consider an ordered --possibly infinite-- sequence of null hypotheses where, at each step , the statistician must decide whether to reject hypothesis having access only to the previous decisions. To the best of our knowledge, our work is the first that controls FDR in this setting. This model was introduced by Foster and Stine cite whose alpha-investing rule only controls mFDR in online manner. In order to compare different procedures, we develop lower bounds on the total discovery rate under the mixture model and prove that both LOND and LORD have nearly linear number of discoveries. We further propose adjustment to LOND to address arbitrary correlation among the -values. Finally, we evaluate the performance of our procedures on both synthetic and real data comparing them with alpha-investing rule, Benjamin-Hochberg method and a Bonferroni procedure.",
        "subjects": "Methodology (stat.ME)",
        "authors": "Adel Javanmard, Andrea Montanari,",
        "date": "2015-2-2"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.07417",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.07417",
        "title": "\nAn improved rate region for the classical-quantum broadcast channel",
        "abstract": "We present a new achievable rate region for the two-user binary-input classical-quantum broadcast channel. The result is a generalization of the classical Marton-Gelfand-Pinsker region and is provably larger than the best previously known rate region for classical-quantum broadcast channels. The proof of achievability is based on the recently introduced polar coding scheme and its generalization to quantum network information theory.",
        "subjects": "Quantum Physics (quant-ph)",
        "authors": "Christoph Hirche, Ciara Morgan,",
        "date": "2015-1-29"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06189",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06189",
        "title": "\nTwo-stage Sampling, Prediction and Adaptive Regression via Correlation  Screening (SPARCS)",
        "abstract": "This paper proposes a general adaptive procedure for budget-limited predictor design in high dimensions called two-stage Sampling, Prediction and Adaptive Regression via Correlation Screening (SPARCS). SPARCS can be applied to high dimensional prediction problems in experimental science, medicine, finance, and engineering, as illustrated by the following. Suppose one wishes to run a sequence of experiments to learn a sparse multivariate predictor of a dependent variable (disease prognosis for instance) based on a dimensional set of independent variables (assayed biomarkers). Assume that the cost of acquiring the full set of variables increases linearly in its dimension. SPARCS breaks the data collection into two stages in order to achieve an optimal tradeoff between sampling cost and predictor performance. In the first stage we collect a few () expensive samples , at the full dimension of , winnowing the number of variables down to a smaller dimension using a type of cross-correlation or regression coefficient screening. In the second stage we collect a larger number of cheaper samples of the variables that passed the screening of the first stage. At the second stage, a low dimensional predictor is constructed by solving the standard regression problem using all samples of the selected variables. SPARCS is an adaptive online algorithm that implements false positive control on the selected variables, is well suited to small sample sizes, and is scalable to high dimensions. We establish asymptotic bounds for the Familywise Error Rate (FWER), specify high dimensional convergence rates for support recovery, and establish optimal sample allocation rules to the first and second stages.",
        "subjects": "Machine Learning (stat.ML)",
        "authors": "Hamed Firouzi, Bala Rajaratnam, Alfred Hero,",
        "date": "2015-2-22"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.07396",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.07396",
        "title": "\nA MILP model for single machine family scheduling with  sequence-dependent batch setup and controllable processing times",
        "abstract": "A mathematical programming model for a class of single machine family scheduling problem is described in this technical report, with the aim of comparing the performance in solving the scheduling problem by means of mathematical programming with the performance obtained when using optimal control strategies, that can be derived from the application of a dynamic programming-based methodology proposed by the Author. The scheduling problem is characterized by the presence of sequence-dependent batch setup and controllable processing times; moreover, the generalized due-date model is adopted in the problem. Three mixed-integer linear programming (MILP) models are proposed. The best one, from the performance point of view, is a model which makes use of two sets of binary variables: the former to define the relative position of jobs and the latter to define the exact sequence of jobs. In addition, one of the model exploits a stage-based state space representation which can be adopted to define the dynamics of the system.",
        "subjects": "Optimization and Control (math.OC)",
        "authors": "Davide Giglio,",
        "date": "2015-1-9"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06144",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06144",
        "title": "\nDetection of Planted Solutions for Flat Satisfiability Problems",
        "abstract": "We study the detection problem of finding planted solutions in random instances of flat satisfiability problems, a generalization of boolean satisfiability formulas. We describe the properties of random instances of flat satisfiability, as well of the optimal rates of detection of the associated hypothesis testing problem. We also study the performance of an algorithmically efficient testing procedure. We introduce a modification of our model, the light planting of solutions, and show that it is as hard as the problem of learning parity with noise. This hints strongly at the difficulty of detecting planted flat satisfiability for a wide class of tests.",
        "subjects": "Statistics Theory (math.ST)",
        "authors": "Quentin Berthet, Jordan S. Ellenberg,",
        "date": "2015-2-21"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.07349",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.07349",
        "title": "\nStructure-Based Self-Triggered Consensus in Networks of Multiagents with  Switching Topologies",
        "abstract": "In this paper, we propose a new self-triggered consensus algorithm in networks of multi-agents. Different from existing works, which are based on the observation of states, here, each agent determines its next update time based on its coupling structure. Both centralized and distributed approaches of the algorithms have been discussed. By transforming the algorithm to a proper discrete-time systems without self delays, we established a new analysis framework to prove the convergence of the algorithm. Then we extended the algorithm to networks with switching topologies, especially stochastically switching topologies. Compared to existing works, our algorithm is easier to understand and implement. It explicitly provides positive lower and upper bounds for the update time interval of each agent based on its coupling structure, which can also be independently adjusted by each agent according to its own situation. Our work reveals that the event/self triggered algorithms are essentially discrete and more suitable to a discrete analysis framework. Numerical simulations are also provided to illustrate the theoretical results.",
        "subjects": "Optimization and Control (math.OC)",
        "authors": "Bo Liu, Wenlian Lu, Licheng Jiao, Tianping Chen,",
        "date": "2015-1-29"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06134",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06134",
        "title": "\nLearning with Square Loss: Localization through Offset Rademacher  Complexity",
        "abstract": "We consider regression with square loss and general classes of functions without the boundedness assumption. We introduce a notion of offset Rademacher complexity that provides a transparent way to study localization both in expectation and in high probability. For any (possibly non-convex) class, the excess loss of a two-step estimator is shown to be upper bounded by this offset complexity through a novel geometric inequality. In the convex case, the estimator reduces to an empirical risk minimizer. The method recovers the results of citep for the bounded case while also providing guarantees without the boundedness assumption.",
        "subjects": "Machine Learning (stat.ML)",
        "authors": "Tengyuan Liang, Alexander Rakhlin, Karthik Sridharan,",
        "date": "2015-2-1"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.07255",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.07255",
        "title": "\nElliptic-cylindrical Wavelets: The Mathieu Wavelets",
        "abstract": "This note introduces a new family of wavelets and a multiresolution analysis, which exploits the relationship between analysing filters and Floquet's solution of Mathieu differential equations. The transfer function of both the detail and the smoothing filter is related to the solution of a Mathieu equation of odd characteristic exponent. The number of notches of these filters can be easily designed. Wavelets derived by this method have potential application in the fields of Optics and Electromagnetism.",
        "subjects": "Methodology (stat.ME)",
        "authors": "M. M. S. Lira, H. M. de Oliveira, R. J. Cintra,",
        "date": "2015-1-28"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06064",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06064",
        "title": "\nMILJS : Brand New JavaScript Libraries for Matrix Calculation and  Machine Learning",
        "abstract": "MILJS is a collection of state-of-the-art, platform-independent, scalable, fast JavaScript libraries for matrix calculation and machine learning. Our core library offering a matrix calculation is called Sushi, which exhibits far better performance than any other leading machine learning libraries written in JavaScript. Especially, our matrix multiplication is 177 times faster than the fastest JavaScript benchmark. Based on Sushi, a machine learning library called Tempura is provided, which supports various algorithms widely used in machine learning research. We also provide Soba as a visualization library. The implementations of our libraries are clearly written, properly documented and thus can are easy to get started with, as long as there is a web browser. These libraries are available from this http URL under the MIT license.",
        "subjects": "Machine Learning (stat.ML)",
        "authors": "Ken Miura, Tetsuaki Mano, Atsushi Kanehira, Yuichiro Tsuchiya, Tatsuya Harada,",
        "date": "2015-2-21"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.07116",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.07116",
        "title": "\nPeer-review Platform for Astronomy Education Activities",
        "abstract": "Hundreds of thousands of astronomy education activities exist, but their discoverability and quality is highly variable. The web platform for astronomy education activities, astroEDU, presented in this paper tries to solve these issues. Using the familiar peer-review workflow of scientific publications, astroEDU is improving standards of quality, visibility and accessibility, while providing credibility to these astronomy education activities. astroEDU targets activity guides, tutorials and other educational activities in the area of astronomy education, prepared by teachers, educators and other education specialists. Each of the astroEDU activities is peer-reviewed by an educator as well as an astronomer to ensure a high standard in terms of scientific content and educational value. All reviewed materials are then stored in a free open online database, enabling broad distribution in a range of different formats. In this way astroEDU is not another web repository for educational resources but a mechanism for peer-reviewing and publishing high-quality astronomy education activities in an open access way. This paper will provide an account on the implementation and first findings of the use of astroEDU.",
        "subjects": "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "authors": "Pedro Russo, Edward Gomez, Thilina Heenatigala, Linda Strubbe,",
        "date": "2015-1-8"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06025",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06025",
        "title": "\nOntoLoki: an automatic, instance-based method for the evaluation of  biological ontologies on the Semantic Web",
        "abstract": "The delineation of logical definitions for each class in an ontology and the consistent application of these definitions to the assignment of instances to classes are important criteria for ontology evaluation. If ontologies are specified with property-based restrictions on class membership, then such consistency can be checked automatically. If no such logical restrictions are applied, as is the case with many biological ontologies, there are currently no automated methods for measuring the semantic consistency of instance assignment on an ontology-wide scale, nor for inferring the patterns of properties that might define a particular class. We constructed a program that takes as its input an OWL/RDF knowledge base containing an ontology, instances associated with each of the classes in the ontology, and properties of those instances. For each class, it outputs: 1) a rule for determining class membership based on the properties of the instances and 2) a quantitative score for the class that reflects the ability of the identified rule to correctly predict class membership for the instances in the knowledge base. We evaluated this program using both artificial knowledge bases of known quality and real, widely used ontologies. The results indicate that the suggested method can be used to conduct objective, automatic, data-driven evaluations of biological ontologies without formal class definitions in regards to the property-based consistency of instance-assignment. This inductive method complements existing, purely deductive approaches to automatic consistency checking, offering not just the potential to help in the ontology engineering process but also in the knowledge discovery process.",
        "subjects": "Quantitative Methods (q-bio.QM)",
        "authors": "Benjamin M. Good, Gavin Ha, Chi K. Ho, Mark D. Wilkinson,",
        "date": "2015-2-20"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.07019",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.07019",
        "title": "\nKangaroo Methods for Solving the Interval Discrete Logarithm Problem",
        "abstract": "The interval discrete logarithm problem is defined as follows: Given some in a group , and some such that for some where , find . At the moment, kangaroo methods are the best low memory algorithm to solve the interval discrete logarithm problem. The fastest non parallelised kangaroo methods to solve this problem are the three kangaroo method, and the four kangaroo method. These respectively have expected average running times of , and group operations. It is currently an open question as to whether it is possible to improve kangaroo methods by using more than four kangaroos. Before this dissertation, the fastest kangaroo method that used more than four kangaroos required at least group operations to solve the interval discrete logarithm problem. In this thesis, I improve the running time of methods that use more than four kangaroos significantly, and almost beat the fastest kangaroo algorithm, by presenting a seven kangaroo method with an expected average running time of group operations. The question, 'Are five kangaroos worse than three?' is also answered in this thesis, as I propose a five kangaroo algorithm that requires on average group operations to solve the interval discrete logarithm problem.",
        "subjects": "Number Theory (math.NT)",
        "authors": "Alex Fowler, Steven Galbraith,",
        "date": "2015-1-28"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06021",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06021",
        "title": "\nA point on fixpoints in posets",
        "abstract": "Let be a , that is, a non-empty partially ordered set such that every non-empty chain has a least upper bound lub, a chain being a subset of totally ordered by . We are interested in sufficient conditions such that, given an element and a function , there is some ordinal such that , where is the transfinite sequence of iterates of starting from (implying that is a fixpoint of ): begin itemsep=0mm item item if is a limit ordinal, i.e. end This note summarizes known results about this problem and provides a slight generalization of some of them.",
        "subjects": "Logic (math.LO)",
        "authors": "Fr\u00e9d\u00e9ric Blanqui,",
        "date": "2014-12-23"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.06957",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.06957",
        "title": "\nCongestion control in charging of electric vehicles",
        "abstract": "The increasing penetration of electric vehicles over the coming decades, taken together with the high cost to upgrade local distribution networks, and consumer demand for home charging, suggest that managing congestion on low voltage networks will be a crucial component of the electric vehicle revolution and the move away from fossil fuels in transportation. Here, we model the max-flow and proportional fairness protocols for the control of congestion caused by a fleet of vehicles charging on distribution networks. We analyse the inequality in the charging times as the vehicle arrival rate increases, and show that charging times are considerably more uneven in max-flow than in proportional fairness. We also analyse the onset of instability, and find that the critical arrival rate is indistinguishable between the two protocols.",
        "subjects": "Optimization and Control (math.OC)",
        "authors": "Rui Carvalho, Lubos Buzna, Richard Gibbens, Frank Kelly,",
        "date": "2015-1-28"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06013",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06013",
        "title": "\nNovel structures in Stanley sequences",
        "abstract": "Given a set of integers with no three in arithmetic progression, we construct a Stanley sequence by adding integers greedily so that no arithmetic progression is formed. This paper offers two main contributions to the theory of Stanley sequences. First, we characterize well-structured Stanley sequences as solutions to constraints in modular arithmetic, defining the modular Stanley sequences. Second, we introduce the basic Stanley sequences, where elements arise as the sums of subsets of a basis sequence, which in the simplest case is the powers of 3. Applications of our results include the construction of Stanley sequences with arbitrarily large gaps between terms, answering a weak version of a problem by Erd Hs et al. Finally, we generalize many results about Stanley sequences to -free sequences, where is any odd prime.",
        "subjects": "Combinatorics (math.CO)",
        "authors": "Richard A. Moy, David Rolnick,",
        "date": "2015-2-20"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.06929",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.06929",
        "title": "\nA Probabilistic Least-Mean-Squares Filter",
        "abstract": "We introduce a probabilistic approach to the LMS filter. By means of an efficient approximation, this approach provides an adaptable step-size LMS algorithm together with a measure of uncertainty about the estimation. In addition, the proposed approximation preserves the linear complexity of the standard LMS. Numerical results show the improved performance of the algorithm with respect to standard LMS and state-of-the-art algorithms with similar complexity. The goal of this work, therefore, is to open the door to bring some more Bayesian machine learning techniques to adaptive filtering.",
        "subjects": "Machine Learning (stat.ML)",
        "authors": "Jesus Fernandez-Bes, V\u00edctor Elvira, Steven Van Vaerenbergh,",
        "date": "2015-1-27"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.06004",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.06004",
        "title": "\nThe Impact of Stealthy Attacks on Smart Grid Performance: Tradeoffs and  Implications",
        "abstract": "The smart grid is envisioned to significantly enhance the efficiency of energy consumption, by utilizing two-way communication channels between consumers and operators. For example, operators can opportunistically leverage the delay tolerance of energy demands in order to balance the energy load over time, and hence, reduce the total operational cost. This opportunity, however, comes with security threats, as the grid becomes more vulnerable to cyber-attacks. In this paper, we study the impact of such malicious cyber-attacks on the energy efficiency of the grid in a simplified setup. More precisely, we consider a simple model where the energy demands of the smart grid consumers are intercepted and altered by an active attacker before they arrive at the operator, who is equipped with limited intrusion detection capabilities. We formulate the resulting optimization problems faced by the operator and the attacker and propose several scheduling and attack strategies for both parties. Interestingly, our results show that, as opposed to facilitating cost reduction in the smart grid, increasing the delay tolerance of the energy demands potentially allows the attacker to force increased costs on the system. This highlights the need for carefully constructed and robust intrusion detection mechanisms at the operator.",
        "subjects": "Optimization and Control (math.OC)",
        "authors": "Yara Abdallah, Zizhan Zheng, Ness B. Shroff, Hesham El Gamal,",
        "date": "2014-12-9"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.06845",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.06845",
        "title": "\nExact Solution for One Type of Lindley's Equation for Queueing Theory  and Network Calculus",
        "abstract": "Lindley's equation is an important relation in queueing theory and network calculus. In this paper, we develop a new method to solve one type of Lindley's equation, i.e., the equation V(s)T(-s)-1=0 only has finite negative real roots. V(s) and T(-s) are the Laplace transforms of service time's probability density function (PDF) and interarrival time's PDF (evaluated at -s). For queueing theory, we use this method to derive the exact M/M/1, M/H2/1 and M/E2/1 waiting-time distributions, and for the first time find the exact D/M/1 waiting-time distribution. For network calculus, we use two examples to compare our method with the effective bandwidth model and its dual, the effective capacity model, respectively. We observe that the distribution function of backlog size in the first example can be obtained exactly by our method and partially by the effective bandwidth model; however, such a distribution function in the second example cannot be obtained by our method but can be approximated by the effective capacity model.",
        "subjects": "Applications (stat.AP)",
        "authors": "Yu Chen,",
        "date": "2015-1-26"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.05974",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.05974",
        "title": "\nDevelopment of a VO Registry Subject Ontology using Automated Methods",
        "abstract": "We report on our initial work to automate the generation of a domain ontology using subject fields of resources held in the Virtual Observatory registry. Preliminary results are comparable to more generalized ontology learning software currently in use. We expect to be able to refine our solution to improve both the depth and breadth of the generated ontology.",
        "subjects": "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
        "authors": "Brian Thomas,",
        "date": "2015-2-20"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.06835",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.06835",
        "title": "\nEmergence of Soft Communities from Geometric Preferential Attachment",
        "abstract": "All real networks are different, but many have some structural properties in common. There seems to be no consensus on what the most common properties are, but scale-free degree distributions, strong clustering, and community structure are frequently mentioned without question. Surprisingly, there exists no simple generative mechanism explaining all the three properties at once in growing networks. Here we show how latent network geometry coupled with preferential attachment of nodes to this geometry fills this gap. We call this mechanism geometric preferential attachment (GPA), and validate it against the Internet. GPA gives rise to soft communities that provide a different perspective on the community structure in networks. The connections between GPA and cosmological models, including inflation, are also discussed.",
        "subjects": "Physics and Society (physics.soc-ph)",
        "authors": "Konstantin Zuev, Marian Boguna, Ginestra Bianconi, Dmitri Krioukov,",
        "date": "2015-1-27"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.05925",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.05925",
        "title": "\nFeature-Budgeted Random Forest",
        "abstract": "We seek decision rules for prediction-time cost reduction, where complete data is available for training, but during prediction-time, each feature can only be acquired for an additional cost. We propose a novel random forest algorithm to minimize prediction error for a user-specified feature acquisition budget. While random forests yield strong generalization performance, they do not explicitly account for feature costs and furthermore require low correlation among trees, which amplifies costs. Our random forest grows trees with low acquisition cost and high strength based on greedy minimax cost-weighted-impurity splits. Theoretically, we establish near-optimal acquisition cost guarantees for our algorithm. Empirically, on a number of benchmark datasets we demonstrate superior accuracy-cost curves against state-of-the-art prediction-time algorithms.",
        "subjects": "Machine Learning (stat.ML)",
        "authors": "Feng Nan, Joseph Wang, Venkatesh Saligrama,",
        "date": "2015-2-20"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.06831",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.06831",
        "title": "\nSome Notes about Subshifts on Groups",
        "abstract": "In this note we prove the following results: If a finitely presented group G admits a strongly aperiodic SFT, then G has decidable word problem. For a large class of group G, Z \u00d7 G admits a strongly aperiodic SFT. In particular, this is true for the free group with 2 generators, Thompson's groups T and V , PSL2(Z) and any f.g. group of rational matrices which is bounded.",
        "subjects": "Group Theory (math.GR)",
        "authors": "Emmanuel Jeandel,",
        "date": "2015-1-27"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.05760",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.05760",
        "title": "\nBidirectional selection between two classes in complex social networks",
        "abstract": "The bidirectional selection between two classes widely emerges in various social lives, such as commercial trading and mate choosing. Until now, the discussions on bidirectional selection in structured human society are quite limited. We demonstrated theoretically that the rate of successfully matching is affected greatly by individuals neighborhoods in social networks, regardless of the type of networks. Furthermore, it is found that the high average degree of networks contributes to increasing rates of successful matches. The matching performance in different types of networks has been quantitatively investigated, revealing that the small-world networks reinforces the matching rate more than scale-free networks at given average degree. In addition, our analysis is consistent with the modeling result, which provides the theoretical understanding of underlying mechanisms of matching in complex networks.",
        "subjects": "Physics and Society (physics.soc-ph)",
        "authors": "Bin Zhou, Zhe He, Luo-Luo Jiang, Nian-Xin Wang, Bing-Hong Wang,",
        "date": "2015-2-20"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.06809",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.06809",
        "title": "\nThe nested assembly of collective attention in online social systems",
        "abstract": "Online social networks have changed the way in which we communicate. These networks are characterized by a competitive information flow and a dynamic topology, where the success of a given topic or meme depends on many factors, most of which are unknown. Likely, given the many sources of information to which a typical individual is exposed, the economy of attention rules the system dynamics. Here we show, using microblogging data, that competition is minimized through consensus and that collective attention and successful topical assembly are characterized by a nested structure of the bipartite network made up by users and memes. Our results indicate that social phenomena could emerge as a result of a topological transition that minimizes modularity while maximizing the nestedness of the system, and that online social networks are comparable to an ecosystem, where generalists and specialists share resources.",
        "subjects": "Physics and Society (physics.soc-ph)",
        "authors": "Javier Borge-Holthoefer, Raquel A. Ba\u00f1os, Carlos Gracia-L\u00e1zaro, Yamir Moreno,",
        "date": "2015-1-27"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.05680",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.05680",
        "title": "\nFinding One Community in a Sparse Graph",
        "abstract": "We consider a random sparse graph with bounded average degree, in which a subset of vertices has higher connectivity than the background. In particular, the average degree inside this subset of vertices is larger than outside (but still bounded). Given a realization of such graph, we aim at identifying the hidden subset of vertices. This can be regarded as a model for the problem of finding a tightly knitted community in a social network, or a cluster in a relational dataset. In this paper we present two sets of contributions: We use the cavity method from spin glass theory to derive an exact phase diagram for the reconstruction problem. In particular, as the difference in edge probability increases, the problem undergoes two phase transitions, a static phase transition and a dynamic one. We establish rigorous bounds on the dynamic phase transition and prove that, above a certain threshold, a local algorithm (belief propagation) correctly identify most of the hidden set. Below the same threshold no local algorithm can achieve this goal. However, in this regime the subset can be identified by exhaustive search. For small hidden sets and large average degree, the phase transition for local algorithms takes an intriguingly simple form. Local algorithms succeed with high probability for and fail for (with , the average degrees inside and outside the community). We argue that spectral algorithms are also ineffective in the latter regime. It is an open problem whether any polynomial time algorithms might succeed for .",
        "subjects": "Machine Learning (stat.ML)",
        "authors": "Andrea Montanari,",
        "date": "2015-2-19"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.06794",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.06794",
        "title": "\nComputing Functions of Random Variables via Reproducing Kernel Hilbert  Space Representations",
        "abstract": "We describe a method to perform functional operations on probability distributions of random variables. The method uses reproducing kernel Hilbert space representations of probability distributions, and it is applicable to all operations which can be applied to points drawn from the respective distributions. We refer to our approach as . We illustrate it on synthetic data, and show how it can be used for nonparametric structural equation models, with an application to causal inference.",
        "subjects": "Machine Learning (stat.ML)",
        "authors": "Bernhard Sch\u00f6lkopf, Krikamol Muandet, Kenji Fukumizu, Jonas Peters,",
        "date": "2015-1-27"
    },
    {
        "urllink": "http://arxiv.org/abs/1502.05632",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1502.05632",
        "title": "\nCapturing k-ary Existential Second Order Logic with k-ary  Inclusion-Exclusion Logic",
        "abstract": "In this paper we analyze k-ary inclusion-exclusion logic, INEX[k], which is obtained by extending first order logic with k-ary inclusion and exclusion atoms. We show that every formula of INEX[k] can be expressed with a formula of k-ary existential second order logic, ESO[k]. Conversely, every formula of ESO[k] with at most k-ary free relation variables can be expressed with a formula of INEX[k]. From this it follows that, on the level of sentences, INEX[k] captures the expressive power of ESO[k]. We also introduce several useful operators that can be expressed in INEX[k]. In particular, we define inclusion and exclusion quantifiers and so-called term value preserving disjunction. The latter one is needed in the proofs of the main results in this paper.",
        "subjects": "Logic (math.LO)",
        "authors": "Raine Ronnholm,",
        "date": "2015-2-19"
    },
    {
        "urllink": "http://arxiv.org/abs/1501.06789",
        "category": "Computer Science ",
        "pdflink": "http://arxiv.org/pdf/1501.06789",
        "title": "\nCan Science and Technology Capacity be Measured?",
        "abstract": "The ability of a nation to participate in the global knowledge economy depends to some extent on its capacities in science and technology. In an effort to assess the capacity of different countries in science and technology, this article updates a classification scheme developed by RAND to measure science and technology capacity for 150 countries of the world.",
        "subjects": "Applications (stat.AP)",
        "authors": "Caroline S. Wagner, Edwin Horlings, Arindum Dutta,",
        "date": "2015-1-27"
    }
]